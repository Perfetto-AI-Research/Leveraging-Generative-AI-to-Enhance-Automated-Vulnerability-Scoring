{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1T89HpOnxc1",
        "outputId": "08869461-d332-4966-e085-d3e56beded13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA GeForce RTX 2080 Ti\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# This will make only the GPUs with index 4 and 5 visible to PyTorch\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '3, 4'\n",
        "\n",
        "# Check if CUDA is available and then set the device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')  # This will use the first available GPU in the list, i.e., GPU 4\n",
        "    print(f'Using GPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('Using CPU')\n",
        "\n",
        "print(f'Using device: {device}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJnnp-r7nxc3"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18Gf6G8mFqYc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/home/leili/Vul/LLMDatasets/Datasets/CSDatasets/GPT35turbo_6370.csv')\n",
        "\n",
        "df['av'] = df['av'].map({'N': 0, 'L': 1, 'A': 2, 'P': 3})  # Adjust mapping as needed\n",
        "df['ac'] = df['ac'].map({'L': 0, 'H': 1})\n",
        "df['pr'] = df['pr'].map({'L': 0, 'H': 1, 'N': 2})\n",
        "df['ui'] = df['ui'].map({'R': 0, 'N': 1})\n",
        "df['s'] = df['s'].map({'C': 0, 'U': 1})\n",
        "df['c'] = df['c'].map({'H': 0, 'N': 1, 'L': 2})\n",
        "df['i'] = df['i'].map({'H': 0, 'N': 1, 'L': 2})\n",
        "df['a'] = df['a'].map({'H': 0, 'N': 1, 'L': 2})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cIehVbwSEv-",
        "outputId": "0240fe2e-6a48-4871-e59b-1a2607cb08b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>[[0.2312672, 0.16543698, -0.02574309, 0.093568...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>[[0.120389976, 0.28464466, 0.05642592, 0.11305...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1  CVE-2016-0003  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                                       layer_output  \n",
              "0    7.5         HIGH  [[0.2312672, 0.16543698, -0.02574309, 0.093568...  \n",
              "1    9.6     CRITICAL  [[0.120389976, 0.28464466, 0.05642592, 0.11305...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-AV', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYBUnmVJnxc7",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 15.29977663225145, Val Loss 1.7440473267342895, Val Accuracy 0.9905808477237049, Precision 0.9711090921439286, Recall 0.9923876260227809, F1 0.9814211118341947, Cohen Kappa 0.9769876177487965, Accuracy 0.9905808477237049\n",
            "Epoch 2: Loss 3.844976712753123, Val Loss 3.0039173747063614, Val Accuracy 0.9803767660910518, Precision 0.8942034442921987, Recall 0.8902634430162449, F1 0.8767195969816522, Cohen Kappa 0.9518262902915984, Accuracy 0.9803767660910518\n",
            "Epoch 3: Loss 2.9730100825572663, Val Loss 2.6568458316032775, Val Accuracy 0.9693877551020408, Precision 0.9524904740291635, Recall 0.9719724631869253, F1 0.9610198196011162, Cohen Kappa 0.9237406759370108, Accuracy 0.9693877551020408\n",
            "Epoch 4: Loss 2.6396143695692444, Val Loss 1.5507828938643797, Val Accuracy 0.989010989010989, Precision 0.9610161289033649, Recall 0.9907536390946763, F1 0.9751682213410786, Cohen Kappa 0.9731133277156127, Accuracy 0.989010989010989\n",
            "Epoch 5: Loss 1.5526924595878882, Val Loss 1.5658689897536533, Val Accuracy 0.9897959183673469, Precision 0.9612871113032988, Recall 0.9915706325587286, F1 0.9757229815500492, Cohen Kappa 0.9750572289156626, Accuracy 0.9897959183673469\n",
            "Epoch 6: Loss 1.6664775179838216, Val Loss 2.4515203451155685, Val Accuracy 0.9772370486656201, Precision 0.9117681196174466, Recall 0.8958233454845879, F1 0.9015902471165629, Cohen Kappa 0.944939881850101, Accuracy 0.9772370486656201\n",
            "Epoch 7: Loss 1.7523255260671249, Val Loss 2.1772279353472186, Val Accuracy 0.9905808477237049, Precision 0.952314267812388, Recall 0.9923876260227809, F1 0.9711070780138171, Cohen Kappa 0.9770288686777926, Accuracy 0.9905808477237049\n",
            "Epoch 8: Loss 1.2739957931985373, Val Loss 2.3839981681264817, Val Accuracy 0.9874411302982732, Precision 0.9405873306260303, Recall 0.9924069735536841, F1 0.9645784067462193, Cohen Kappa 0.9695841546337759, Accuracy 0.9874411302982732\n",
            "Epoch 9: Loss 1.5985873431252458, Val Loss 2.1982890449544357, Val Accuracy 0.9897959183673469, Precision 0.9520457393483709, Recall 0.9921185194565806, F1 0.9708382608095159, Cohen Kappa 0.9751146077342754, Accuracy 0.9897959183673469\n",
            "Epoch 10: Loss 0.5960336772507162, Val Loss 2.265413533148603, Val Accuracy 0.9897959183673469, Precision 0.9520457393483709, Recall 0.9921185194565806, F1 0.9708382608095159, Cohen Kappa 0.9751146077342754, Accuracy 0.9897959183673469\n",
            "Epoch 11: Loss 0.4041598721579476, Val Loss 3.441685772500932, Val Accuracy 0.978806907378336, Precision 0.8904347888558415, Recall 0.9861594799383693, F1 0.9279628490974672, Cohen Kappa 0.948799852344478, Accuracy 0.978806907378336\n",
            "Epoch 12: Loss 0.2561076190053768, Val Loss 2.217201630863201, Val Accuracy 0.9913657770800628, Precision 0.9713838544068091, Recall 0.9932046194868331, F1 0.9819733616281026, Cohen Kappa 0.9789250798167111, Accuracy 0.9913657770800628\n",
            "Epoch 13: Loss 0.8586782688591086, Val Loss 2.42799300670049, Val Accuracy 0.9882260596546311, Precision 0.9430216367483447, Recall 0.9910324194263281, F1 0.9650769378328985, Cohen Kappa 0.9712983767287058, Accuracy 0.9882260596546311\n",
            "Epoch 14: Loss 0.5375652040972128, Val Loss 2.7845573496338396, Val Accuracy 0.9858712715855573, Precision 0.9706384706505666, Recall 0.9863898914427629, F1 0.9780388492215435, Cohen Kappa 0.9651546554668838, Accuracy 0.9858712715855573\n",
            "Epoch 15: Loss 0.9997437985204982, Val Loss 2.1740943607826466, Val Accuracy 0.9897959183673469, Precision 0.9618548068743249, Recall 0.9910227456608764, F1 0.9757096341395874, Cohen Kappa 0.9750103356599885, Accuracy 0.9897959183673469\n",
            "Epoch 16: Loss 0.14284125627531807, Val Loss 2.849434410080221, Val Accuracy 0.989010989010989, Precision 0.9432937181663836, Recall 0.9918494128903804, F1 0.9656304485189549, Cohen Kappa 0.9732368603878224, Accuracy 0.989010989010989\n",
            "Epoch 17: Loss 0.10507426601463976, Val Loss 2.8528293091243597, Val Accuracy 0.989010989010989, Precision 0.9432937181663836, Recall 0.9918494128903804, F1 0.9656304485189549, Cohen Kappa 0.9732368603878224, Accuracy 0.989010989010989\n",
            "Epoch 18: Loss 0.3531714412779401, Val Loss 3.2096188465114324, Val Accuracy 0.9795918367346939, Precision 0.9785487231472852, Recall 0.8140853040175524, F1 0.8464940950285522, Cohen Kappa 0.9490250996445114, Accuracy 0.9795918367346939\n",
            "Epoch 19: Loss 0.10542308451652893, Val Loss 2.9765521931518037, Val Accuracy 0.9882260596546311, Precision 0.9515026773514635, Recall 0.990484532528476, F1 0.9697299899112377, Cohen Kappa 0.971232227131427, Accuracy 0.9882260596546311\n",
            "Epoch 20: Loss 0.1509462503349992, Val Loss 9.816303542286732, Val Accuracy 0.9081632653061225, Precision 0.9198411409430035, Recall 0.9066033122972906, F1 0.9001401233850563, Cohen Kappa 0.7514780468773447, Accuracy 0.9081632653061225\n",
            "Epoch 21: Loss 0.7998038324906176, Val Loss 2.5356142968082054, Val Accuracy 0.989010989010989, Precision 0.9604570520815942, Recall 0.9913015259925283, F1 0.9751827389123158, Cohen Kappa 0.9731637334248138, Accuracy 0.989010989010989\n",
            "Epoch 22: Loss 0.09853362764483364, Val Loss 3.1150370205562155, Val Accuracy 0.9874411302982732, Precision 0.9421915676287492, Recall 0.9907633128601279, F1 0.9645364042032807, Cohen Kappa 0.96941355472894, Accuracy 0.9874411302982732\n",
            "Epoch 23: Loss 0.47997270139695214, Val Loss 3.4265362454364094, Val Accuracy 0.9843014128728415, Precision 0.9132167608079557, Recall 0.989686886595327, F1 0.9457321012934687, Cohen Kappa 0.9619741788556735, Accuracy 0.9843014128728415\n",
            "Epoch 24: Loss 0.04333640969703989, Val Loss 3.3338718181342983, Val Accuracy 0.9811616954474097, Precision 0.9796318897769379, Recall 0.8373469409292242, F1 0.8735654241395243, Cohen Kappa 0.9529874842399828, Accuracy 0.9811616954474097\n",
            "Epoch 25: Loss 0.011764202869084972, Val Loss 2.7985322164806945, Val Accuracy 0.9866562009419152, Precision 0.944734262125903, Recall 0.944499471837533, F1 0.9442889811259396, Cohen Kappa 0.9672789957380205, Accuracy 0.9866562009419152\n",
            "Epoch 26: Loss 0.025030226858534066, Val Loss 3.1962314376766514, Val Accuracy 0.9897959183673469, Precision 0.9520457393483709, Recall 0.9921185194565806, F1 0.9708382608095159, Cohen Kappa 0.9751146077342754, Accuracy 0.9897959183673469\n",
            "Epoch 27: Loss 0.014165308212157224, Val Loss 3.1651497771399093, Val Accuracy 0.9905808477237049, Precision 0.9610066278939595, Recall 0.9929355129206329, F1 0.9762884748335152, Cohen Kappa 0.97704052899294, Accuracy 0.9905808477237049\n",
            "Epoch 28: Loss 0.010773933647225675, Val Loss 3.2388475268974695, Val Accuracy 0.9913657770800628, Precision 0.9618306744761658, Recall 0.9932046194868331, F1 0.9768287663276238, Cohen Kappa 0.9789341085853954, Accuracy 0.9913657770800628\n",
            "Epoch 29: Loss 0.006048903967635522, Val Loss 3.556160473246061, Val Accuracy 0.989010989010989, Precision 0.9517739417137011, Recall 0.9913015259925283, F1 0.970284749113336, Cohen Kappa 0.973175236273289, Accuracy 0.989010989010989\n",
            "Epoch 30: Loss 0.0037031703856005294, Val Loss 3.40216930033381, Val Accuracy 0.9897959183673469, Precision 0.9612871113032988, Recall 0.9915706325587286, F1 0.9757229815500492, Cohen Kappa 0.9750572289156626, Accuracy 0.9897959183673469\n",
            "Epoch 31: Loss 0.0023937024538101537, Val Loss 3.725648950767134, Val Accuracy 0.9905808477237049, Precision 0.9615586257582751, Recall 0.9923876260227809, F1 0.9762764941771491, Cohen Kappa 0.9769974857926975, Accuracy 0.9905808477237049\n",
            "Epoch 32: Loss 0.0010344900751551311, Val Loss 3.752746186214064, Val Accuracy 0.9905808477237049, Precision 0.9615586257582751, Recall 0.9923876260227809, F1 0.9762764941771491, Cohen Kappa 0.9769974857926975, Accuracy 0.9905808477237049\n",
            "Epoch 33: Loss 0.5919359987491655, Val Loss 8.088676805500802, Val Accuracy 0.9733124018838305, Precision 0.8108980055347097, Recall 0.7526584009994381, F1 0.7547283827334419, Cohen Kappa 0.9328659970211572, Accuracy 0.9733124018838305\n",
            "Epoch 34: Loss 0.49398012261532287, Val Loss 3.0425450269323164, Val Accuracy 0.978806907378336, Precision 0.9428283110467655, Recall 0.8138161974513523, F1 0.8423908038633012, Cohen Kappa 0.9471383917457332, Accuracy 0.978806907378336\n",
            "Epoch 35: Loss 0.04514279447814973, Val Loss 3.1491744393753756, Val Accuracy 0.9905808477237049, Precision 0.9615586257582751, Recall 0.9923876260227809, F1 0.9762764941771491, Cohen Kappa 0.9769974857926975, Accuracy 0.9905808477237049\n",
            "Epoch 36: Loss 0.39789612869686375, Val Loss 3.3484174844584382, Val Accuracy 0.9905808477237049, Precision 0.952318072469245, Recall 0.9929355129206329, F1 0.9713905321052705, Cohen Kappa 0.977050351720473, Accuracy 0.9905808477237049\n",
            "Epoch 37: Loss 0.04067007656012267, Val Loss 3.0522973626694743, Val Accuracy 0.9905808477237049, Precision 0.952318072469245, Recall 0.9929355129206329, F1 0.9713905321052705, Cohen Kappa 0.977050351720473, Accuracy 0.9905808477237049\n",
            "Epoch 38: Loss 0.4579154056658219, Val Loss 2.756857279815435, Val Accuracy 0.9897959183673469, Precision 0.9514940221573472, Recall 0.9926664063544327, F1 0.9708500950741121, Cohen Kappa 0.9751611108361566, Accuracy 0.9897959183673469\n",
            "Epoch 39: Loss 0.43819560695438575, Val Loss 3.733662469114054, Val Accuracy 0.9897959183673469, Precision 0.9526095563662603, Recall 0.9915706325587286, F1 0.9708263329447913, Cohen Kappa 0.97506793018057, Accuracy 0.9897959183673469\n",
            "Epoch 40: Loss 0.04915707463133545, Val Loss 3.276018834387628, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 41: Loss 0.013492303034775999, Val Loss 3.5119113474583408, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 42: Loss 0.005636496598082186, Val Loss 4.062412645736748, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 43: Loss 0.009833701893961155, Val Loss 3.945441070662566, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 44: Loss 0.002314279877078329, Val Loss 4.041510851850146, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 45: Loss 0.0021639869636121967, Val Loss 4.070078248705019, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 46: Loss 0.0024586706725520657, Val Loss 4.1617098946560045, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 47: Loss 0.003728973829661808, Val Loss 4.175313733711176, Val Accuracy 0.9897959183673469, Precision 0.9435663362978502, Recall 0.9926664063544327, F1 0.9661827188807817, Cohen Kappa 0.9751717231681613, Accuracy 0.9897959183673469\n",
            "Epoch 48: Loss 0.002472279150794121, Val Loss 4.396190674247656, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 49: Loss 0.0006102011086998455, Val Loss 4.377122815460127, Val Accuracy 0.989010989010989, Precision 0.9427422822442038, Recall 0.9923972997882324, F1 0.965642136077457, Cohen Kappa 0.9732868044062695, Accuracy 0.989010989010989\n",
            "Epoch 50: Loss 0.0717161506237888, Val Loss 3.1954927620275395, Val Accuracy 0.9897959183673469, Precision 0.9501370626765682, Recall 0.9810307510158709, F1 0.964924838469879, Cohen Kappa 0.9751272397423517, Accuracy 0.9897959183673469\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['av'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_AV_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_AV_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvhy60n7nxc7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-AV')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhsIMKgqF5cA",
        "outputId": "f7c7ec5c-1139-4c54-b317-b88b389482ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>[[-0.3919131, 0.1805185, 0.2762716, -0.3183832...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>[[0.08500736, -0.6972643, 0.11465511, 0.185235...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1  CVE-2016-0003  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                                       layer_output  \n",
              "0    7.5         HIGH  [[-0.3919131, 0.1805185, 0.2762716, -0.3183832...  \n",
              "1    9.6     CRITICAL  [[0.08500736, -0.6972643, 0.11465511, 0.185235...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-AC', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxouhCb0F5cA",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 3.7982713683741167, Val Loss 3.235708149150014, Val Accuracy 0.9968602825745683, Precision 0.9943209316394435, Recall 0.9866371865880531, F1 0.9904415350564579, Cohen Kappa 0.980883213540807, Accuracy 0.9968602825745683\n",
            "Epoch 2: Loss 2.26817957395906, Val Loss 1.3426147387363017, Val Accuracy 0.9945054945054945, Precision 0.9969957081545064, Recall 0.9698275862068966, F1 0.9829377720380734, Cohen Kappa 0.965878742892999, Accuracy 0.9945054945054945\n",
            "Epoch 3: Loss 1.72816435972436, Val Loss 1.97746428148821, Val Accuracy 0.9850863422291993, Precision 0.991928632115548, Recall 0.9181034482758621, F1 0.9513305385489237, Cohen Kappa 0.9027316783065041, Accuracy 0.9850863422291993\n",
            "Epoch 4: Loss 2.030117667084596, Val Loss 2.8049376318231225, Val Accuracy 0.9882260596546311, Precision 0.9936061381074168, Recall 0.9353448275862069, F1 0.96222028480093, Cohen Kappa 0.9244741647103459, Accuracy 0.9882260596546311\n",
            "Epoch 5: Loss 1.9561270120193512, Val Loss 0.9888046483974904, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 6: Loss 1.8399696229007532, Val Loss 1.7375995563343167, Val Accuracy 0.9945054945054945, Precision 0.9969957081545064, Recall 0.9698275862068966, F1 0.9829377720380734, Cohen Kappa 0.965878742892999, Accuracy 0.9945054945054945\n",
            "Epoch 7: Loss 1.9697223915973154, Val Loss 1.6989107532426715, Val Accuracy 0.9945054945054945, Precision 0.9969957081545064, Recall 0.9698275862068966, F1 0.9829377720380734, Cohen Kappa 0.965878742892999, Accuracy 0.9945054945054945\n",
            "Epoch 8: Loss 1.8061070190015016, Val Loss 0.9673865630757064, Val Accuracy 0.9945054945054945, Precision 0.9969957081545064, Recall 0.9698275862068966, F1 0.9829377720380734, Cohen Kappa 0.965878742892999, Accuracy 0.9945054945054945\n",
            "Epoch 9: Loss 1.762898242661322, Val Loss 0.8165488680824637, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 10: Loss 1.7663664938036163, Val Loss 1.4766044751740992, Val Accuracy 0.9945054945054945, Precision 0.9969957081545064, Recall 0.9698275862068966, F1 0.9829377720380734, Cohen Kappa 0.965878742892999, Accuracy 0.9945054945054945\n",
            "Epoch 11: Loss 1.65116503941681, Val Loss 0.8755374532192945, Val Accuracy 0.9945054945054945, Precision 0.9929159598119186, Recall 0.9737061521052945, F1 0.9830735270950733, Cohen Kappa 0.9661486604465431, Accuracy 0.9945054945054945\n",
            "Epoch 12: Loss 1.6790970770925924, Val Loss 1.6166269900277257, Val Accuracy 0.9882260596546311, Precision 0.9535469333841904, Recall 0.9780090524685844, F1 0.9653710874855713, Cohen Kappa 0.930748323971734, Accuracy 0.9882260596546311\n",
            "Epoch 13: Loss 1.4459469505382003, Val Loss 1.1687405402772129, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 14: Loss 1.517265338148718, Val Loss 1.8260557856410742, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 15: Loss 1.750102665657323, Val Loss 0.6419459986500442, Val Accuracy 0.9976452119309263, Precision 0.9987080103359174, Recall 0.9870689655172413, F1 0.9928029511289876, Cohen Kappa 0.9856061461981697, Accuracy 0.9976452119309263\n",
            "Epoch 16: Loss 1.5885352765362768, Val Loss 4.187972731888294, Val Accuracy 0.9968602825745683, Precision 0.9943209316394435, Recall 0.9866371865880531, F1 0.9904415350564579, Cohen Kappa 0.980883213540807, Accuracy 0.9968602825745683\n",
            "Epoch 17: Loss 1.4529639487918757, Val Loss 1.8996885567903519, Val Accuracy 0.9945054945054945, Precision 0.9929159598119186, Recall 0.9737061521052945, F1 0.9830735270950733, Cohen Kappa 0.9661486604465431, Accuracy 0.9945054945054945\n",
            "Epoch 18: Loss 1.3923677613856853, Val Loss 0.8868247945792973, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 19: Loss 1.5041502600215608, Val Loss 0.8974826424382627, Val Accuracy 0.9945054945054945, Precision 0.9929159598119186, Recall 0.9737061521052945, F1 0.9830735270950733, Cohen Kappa 0.9661486604465431, Accuracy 0.9945054945054945\n",
            "Epoch 20: Loss 1.4083025165491563, Val Loss 1.9023622749373317, Val Accuracy 0.9945054945054945, Precision 0.9969957081545064, Recall 0.9698275862068966, F1 0.9829377720380734, Cohen Kappa 0.965878742892999, Accuracy 0.9945054945054945\n",
            "Epoch 21: Loss 1.3041555638046702, Val Loss 1.67604164686054, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 22: Loss 1.43905695385547, Val Loss 0.8668792941607535, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 23: Loss 1.2874004078039434, Val Loss 0.7692535971291363, Val Accuracy 0.9945054945054945, Precision 0.9889971263710716, Recall 0.9775847180036925, F1 0.9832068859676377, Cohen Kappa 0.9664143411290627, Accuracy 0.9945054945054945\n",
            "Epoch 24: Loss 1.2397588549465581, Val Loss 1.004785167875525, Val Accuracy 0.9945054945054945, Precision 0.9929159598119186, Recall 0.9737061521052945, F1 0.9830735270950733, Cohen Kappa 0.9661486604465431, Accuracy 0.9945054945054945\n",
            "Epoch 25: Loss 1.3605530408785853, Val Loss 0.7894599252613261, Val Accuracy 0.9937205651491365, Precision 0.9884896729776247, Recall 0.9732743731761062, F1 0.9807320024198427, Cohen Kappa 0.9614651704425153, Accuracy 0.9937205651491365\n",
            "Epoch 26: Loss 1.1465732317192305, Val Loss 0.7219272007932886, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 27: Loss 1.156502582696703, Val Loss 1.718136771582067, Val Accuracy 0.9874411302982732, Precision 0.9527478938979963, Recall 0.9736987076409982, F1 0.9629233511586452, Cohen Kappa 0.9258515576120011, Accuracy 0.9874411302982732\n",
            "Epoch 28: Loss 1.296883341470675, Val Loss 1.0176485124975443, Val Accuracy 0.9905808477237049, Precision 0.9649335644136338, Recall 0.9793043892561492, F1 0.9719811154770981, Cohen Kappa 0.9439638741459696, Accuracy 0.9905808477237049\n",
            "Epoch 29: Loss 1.4632551351242, Val Loss 2.2564492132514715, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 30: Loss 1.19489326641542, Val Loss 0.6380944708362222, Val Accuracy 0.9952904238618524, Precision 0.9857736287296766, Recall 0.9857736287296766, F1 0.9857736287296766, Cohen Kappa 0.9715472574593532, Accuracy 0.9952904238618524\n",
            "Epoch 31: Loss 1.3710389846164617, Val Loss 0.6901663071475923, Val Accuracy 0.9937205651491365, Precision 0.9810315049729021, Recall 0.9810315049729021, F1 0.9810315049729021, Cohen Kappa 0.9620630099458043, Accuracy 0.9937205651491365\n",
            "Epoch 32: Loss 1.3520361417686217, Val Loss 1.1857408329378814, Val Accuracy 0.9945054945054945, Precision 0.9889971263710716, Recall 0.9775847180036925, F1 0.9832068859676377, Cohen Kappa 0.9664143411290627, Accuracy 0.9945054945054945\n",
            "Epoch 33: Loss 1.3020403657465067, Val Loss 1.253114216029644, Val Accuracy 0.9945054945054945, Precision 0.9929159598119186, Recall 0.9737061521052945, F1 0.9830735270950733, Cohen Kappa 0.9661486604465431, Accuracy 0.9945054945054945\n",
            "Epoch 34: Loss 1.413945263657297, Val Loss 1.7595731113106012, Val Accuracy 0.9952904238618524, Precision 0.9857736287296766, Recall 0.9857736287296766, F1 0.9857736287296766, Cohen Kappa 0.9715472574593532, Accuracy 0.9952904238618524\n",
            "Epoch 35: Loss 1.1977705434856034, Val Loss 0.8823638579342514, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 36: Loss 1.367495653223159, Val Loss 1.6936745718121529, Val Accuracy 0.9937205651491365, Precision 0.9884896729776247, Recall 0.9732743731761062, F1 0.9807320024198427, Cohen Kappa 0.9614651704425153, Accuracy 0.9937205651491365\n",
            "Epoch 37: Loss 1.2079478157684207, Val Loss 0.9337797889020294, Val Accuracy 0.9945054945054945, Precision 0.9969957081545064, Recall 0.9698275862068966, F1 0.9829377720380734, Cohen Kappa 0.965878742892999, Accuracy 0.9945054945054945\n",
            "Epoch 38: Loss 1.1153762728717993, Val Loss 0.7643427073489875, Val Accuracy 0.9937205651491365, Precision 0.9884896729776247, Recall 0.9732743731761062, F1 0.9807320024198427, Cohen Kappa 0.9614651704425153, Accuracy 0.9937205651491365\n",
            "Epoch 39: Loss 1.3112909506598953, Val Loss 2.566438822541386, Val Accuracy 0.9222919937205651, Precision 0.9606205250596659, Recall 0.5732758620689655, F1 0.6073226544622425, Cohen Kappa 0.23790015589312263, Accuracy 0.9222919937205651\n",
            "Epoch 40: Loss 1.2957297927314357, Val Loss 1.2619185810908675, Val Accuracy 0.9929356357927787, Precision 0.9841416843886488, Recall 0.972842594246918, F1 0.9784088533869628, Cohen Kappa 0.9568184385945091, Accuracy 0.9929356357927787\n",
            "Epoch 41: Loss 1.1389487542019197, Val Loss 0.8206989541649818, Val Accuracy 0.9913657770800628, Precision 0.968856633562516, Recall 0.9797361681853374, F1 0.9742178804352826, Cohen Kappa 0.9484366146396744, Accuracy 0.9913657770800628\n",
            "Epoch 42: Loss 1.1724360310690827, Val Loss 1.0340272756293416, Val Accuracy 0.9929356357927787, Precision 0.9841416843886488, Recall 0.972842594246918, F1 0.9784088533869628, Cohen Kappa 0.9568184385945091, Accuracy 0.9929356357927787\n",
            "Epoch 43: Loss 1.0185802287469414, Val Loss 1.0602043033577502, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 44: Loss 1.1723633046858595, Val Loss 0.7576863340218551, Val Accuracy 0.9945054945054945, Precision 0.9929159598119186, Recall 0.9737061521052945, F1 0.9830735270950733, Cohen Kappa 0.9661486604465431, Accuracy 0.9945054945054945\n",
            "Epoch 45: Loss 1.117535620538547, Val Loss 0.8065046171541326, Val Accuracy 0.9952904238618524, Precision 0.9974226804123711, Recall 0.9741379310344828, F1 0.9854336740527314, Cohen Kappa 0.9708693465038643, Accuracy 0.9952904238618524\n",
            "Epoch 46: Loss 1.1841983051563147, Val Loss 0.9641343443654478, Val Accuracy 0.9921507064364207, Precision 0.9728461673802122, Recall 0.9801679471145257, F1 0.9764717180447517, Cohen Kappa 0.9529437837039226, Accuracy 0.9921507064364207\n",
            "Epoch 47: Loss 1.0437430371348455, Val Loss 0.7643304238445126, Val Accuracy 0.9929356357927787, Precision 0.9841416843886488, Recall 0.972842594246918, F1 0.9784088533869628, Cohen Kappa 0.9568184385945091, Accuracy 0.9929356357927787\n",
            "Epoch 48: Loss 1.07932690049347, Val Loss 1.9066660278913332, Val Accuracy 0.989010989010989, Precision 0.9940273037542662, Recall 0.9396551724137931, F1 0.9648856164113873, Cohen Kappa 0.9297983217091488, Accuracy 0.989010989010989\n",
            "Epoch 49: Loss 1.120556107183802, Val Loss 0.9136500380700454, Val Accuracy 0.9929356357927787, Precision 0.9879815326934845, Recall 0.9689640283485201, F1 0.9782373919793801, Cohen Kappa 0.9564768491455554, Accuracy 0.9929356357927787\n",
            "Epoch 50: Loss 1.0426537273833674, Val Loss 0.7882083492586389, Val Accuracy 0.9945054945054945, Precision 0.9929159598119186, Recall 0.9737061521052945, F1 0.9830735270950733, Cohen Kappa 0.9661486604465431, Accuracy 0.9945054945054945\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['ac'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_AC_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_AC_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HJMqNJMF5cA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-AC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7AR8AicF6Qf",
        "outputId": "d10b51b0-bd31-4f32-f284-98eb0e9c2f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>[[-0.29671663, 0.32430276, -0.122091174, -0.17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>[[-0.296773, 0.32394254, -0.12224019, -0.17117...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1  CVE-2016-0003  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                                       layer_output  \n",
              "0    7.5         HIGH  [[-0.29671663, 0.32430276, -0.122091174, -0.17...  \n",
              "1    9.6     CRITICAL  [[-0.296773, 0.32394254, -0.12224019, -0.17117...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-PR', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9nQekKWF6Qf",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 15.923579172871541, Val Loss 4.2913532219827175, Val Accuracy 0.9772370486656201, Precision 0.9468590498625834, Recall 0.96780358954272, F1 0.9567470350282425, Cohen Kappa 0.9524288383268074, Accuracy 0.9772370486656201\n",
            "Epoch 2: Loss 8.483155760157388, Val Loss 3.217073357431218, Val Accuracy 0.9772370486656201, Precision 0.9526420106064329, Recall 0.9683780770737291, F1 0.9602036675691731, Cohen Kappa 0.9523961072678849, Accuracy 0.9772370486656201\n",
            "Epoch 3: Loss 8.26940171860042, Val Loss 3.383133122464642, Val Accuracy 0.9811616954474097, Precision 0.9653976972055786, Recall 0.9726345074171162, F1 0.968964931780821, Cohen Kappa 0.9605629733578224, Accuracy 0.9811616954474097\n",
            "Epoch 4: Loss 8.095284769457066, Val Loss 2.984753653872758, Val Accuracy 0.9811616954474097, Precision 0.9689381837456864, Recall 0.9720600198861068, F1 0.9704855023091231, Cohen Kappa 0.9604978082329824, Accuracy 0.9811616954474097\n",
            "Epoch 5: Loss 7.913033904478652, Val Loss 3.117627816274762, Val Accuracy 0.9764521193092621, Precision 0.975497712254146, Recall 0.9606576476141694, F1 0.9678808800408857, Cohen Kappa 0.9500811084031441, Accuracy 0.9764521193092621\n",
            "Epoch 6: Loss 7.112459367017436, Val Loss 3.0791144585236907, Val Accuracy 0.9795918367346939, Precision 0.9747764063346746, Recall 0.9623640362770797, F1 0.9684423432638316, Cohen Kappa 0.9570061069395861, Accuracy 0.9795918367346939\n",
            "Epoch 7: Loss 7.356775401945924, Val Loss 4.472469361498952, Val Accuracy 0.9803767660910518, Precision 0.9670909252668727, Recall 0.9650536824449869, F1 0.9660527384626055, Cohen Kappa 0.958877278695848, Accuracy 0.9803767660910518\n",
            "Epoch 8: Loss 7.765434442204423, Val Loss 3.2685583126731217, Val Accuracy 0.9725274725274725, Precision 0.928549753917517, Recall 0.964878925748491, F1 0.9449063058512518, Cohen Kappa 0.9428162515212878, Accuracy 0.9725274725274725\n",
            "Epoch 9: Loss 7.080920033651637, Val Loss 3.3301518270745873, Val Accuracy 0.9795918367346939, Precision 0.9715874016446824, Recall 0.9656713569757048, F1 0.9686023988315641, Cohen Kappa 0.9570358860083868, Accuracy 0.9795918367346939\n",
            "Epoch 10: Loss 6.976637305910117, Val Loss 2.752459700219333, Val Accuracy 0.9795918367346939, Precision 0.9704056574174452, Recall 0.9635130113390983, F1 0.9669052386101468, Cohen Kappa 0.9571335764553024, Accuracy 0.9795918367346939\n",
            "Epoch 11: Loss 6.937341665237909, Val Loss 4.877881101332605, Val Accuracy 0.9740973312401884, Precision 0.9314557842127617, Recall 0.9662368053672402, F1 0.9472912496125009, Cohen Kappa 0.9461004146121953, Accuracy 0.9740973312401884\n",
            "Epoch 12: Loss 7.089265183312818, Val Loss 2.3880236719269305, Val Accuracy 0.9795918367346939, Precision 0.9692400022435358, Recall 0.9607801781714826, F1 0.9648723374241782, Cohen Kappa 0.9572028626173645, Accuracy 0.9795918367346939\n",
            "Epoch 13: Loss 6.8523187065147795, Val Loss 3.3375292726559564, Val Accuracy 0.9764521193092621, Precision 0.9543784309448503, Recall 0.9619462271636184, F1 0.9581112693042021, Cohen Kappa 0.9507358684639954, Accuracy 0.9764521193092621\n",
            "Epoch 14: Loss 6.910064615192823, Val Loss 4.114688593894243, Val Accuracy 0.9748822605965463, Precision 0.9362660292561037, Recall 0.9666285014111101, F1 0.9503352261568415, Cohen Kappa 0.947697928854404, Accuracy 0.9748822605965463\n",
            "Epoch 15: Loss 6.806064869975671, Val Loss 2.7149157519452274, Val Accuracy 0.978806907378336, Precision 0.9650257719771126, Recall 0.9603884821276125, F1 0.962636887730362, Cohen Kappa 0.9556011616650533, Accuracy 0.978806907378336\n",
            "Epoch 16: Loss 6.891045397380367, Val Loss 3.3624153193086386, Val Accuracy 0.9795918367346939, Precision 0.9686633510542902, Recall 0.9701276527363484, F1 0.9693706248186023, Cohen Kappa 0.9571218681837893, Accuracy 0.9795918367346939\n",
            "Epoch 17: Loss 6.592882601835299, Val Loss 2.2062643847893924, Val Accuracy 0.9764521193092621, Precision 0.947126030418922, Recall 0.969709843622887, F1 0.9578455915996994, Cohen Kappa 0.9508844525261352, Accuracy 0.9764521193092621\n",
            "Epoch 18: Loss 6.70453997165896, Val Loss 2.598294305964373, Val Accuracy 0.9764521193092621, Precision 0.9445013407294885, Recall 0.9656884309058222, F1 0.9542980984905127, Cohen Kappa 0.950676870265457, Accuracy 0.9764521193092621\n",
            "Epoch 19: Loss 6.254600314132404, Val Loss 2.822863696143031, Val Accuracy 0.9748822605965463, Precision 0.9407204588097748, Recall 0.9637560637560637, F1 0.9512331421552088, Cohen Kappa 0.9473724296489645, Accuracy 0.9748822605965463\n",
            "Epoch 20: Loss 6.43034533970058, Val Loss 2.4696475049713627, Val Accuracy 0.9819466248037677, Precision 0.9724815386359079, Recall 0.9730262034609861, F1 0.9727530821222197, Cohen Kappa 0.9621554182509505, Accuracy 0.9819466248037677\n",
            "Epoch 21: Loss 6.604011564486427, Val Loss 2.7152964384295046, Val Accuracy 0.978806907378336, Precision 0.97446985844674, Recall 0.9652796609318348, F1 0.9698117887617584, Cohen Kappa 0.9553679632335196, Accuracy 0.978806907378336\n",
            "Epoch 22: Loss 6.910837909672409, Val Loss 2.878809292567894, Val Accuracy 0.9795918367346939, Precision 0.9686400787274714, Recall 0.9695531652053391, F1 0.9690647776494444, Cohen Kappa 0.9570937644509325, Accuracy 0.9795918367346939\n",
            "Epoch 23: Loss 6.159301900130231, Val Loss 2.438129562418908, Val Accuracy 0.9795918367346939, Precision 0.9656387465714434, Recall 0.9695531652053391, F1 0.9675186799612643, Cohen Kappa 0.957108598480336, Accuracy 0.9795918367346939\n",
            "Epoch 24: Loss 6.643737254082225, Val Loss 2.6304472964257, Val Accuracy 0.9827315541601256, Precision 0.9734449297727096, Recall 0.9739923870358652, F1 0.9737178674574826, Cohen Kappa 0.9638008348487354, Accuracy 0.9827315541601256\n",
            "Epoch 25: Loss 6.12173760071164, Val Loss 2.7340018432587385, Val Accuracy 0.9795918367346939, Precision 0.9607266664442702, Recall 0.9752980405154319, F1 0.9678045944375508, Cohen Kappa 0.9576633827371306, Accuracy 0.9795918367346939\n",
            "Epoch 26: Loss 5.774352067295695, Val Loss 2.675252421759069, Val Accuracy 0.9819466248037677, Precision 0.969357088643566, Recall 0.9730262034609861, F1 0.971178611220869, Cohen Kappa 0.9621684640799236, Accuracy 0.9819466248037677\n",
            "Epoch 27: Loss 5.985336951969657, Val Loss 2.7851608428172767, Val Accuracy 0.9819466248037677, Precision 0.9663394892840858, Recall 0.9730262034609861, F1 0.9696313374983686, Cohen Kappa 0.9621815009176491, Accuracy 0.9819466248037677\n",
            "Epoch 28: Loss 6.132445127994288, Val Loss 4.214606972411275, Val Accuracy 0.9819466248037677, Precision 0.9693841102269648, Recall 0.9736006909919954, F1 0.9714783464613181, Cohen Kappa 0.9621931629776336, Accuracy 0.9819466248037677\n",
            "Epoch 29: Loss 6.75696339487331, Val Loss 2.5311615550890565, Val Accuracy 0.978806907378336, Precision 0.9468041937604538, Recall 0.9724687898600942, F1 0.9586757947570373, Cohen Kappa 0.955711204815399, Accuracy 0.978806907378336\n",
            "Epoch 30: Loss 6.222594170307275, Val Loss 2.6420038556680083, Val Accuracy 0.9819466248037677, Precision 0.9693841102269648, Recall 0.9736006909919954, F1 0.9714783464613181, Cohen Kappa 0.9621931629776336, Accuracy 0.9819466248037677\n",
            "Epoch 31: Loss 6.06850970024243, Val Loss 2.665522947558202, Val Accuracy 0.9803767660910518, Precision 0.9735680218033159, Recall 0.9611718742153524, F1 0.9671343589752722, Cohen Kappa 0.958807766126404, Accuracy 0.9803767660910518\n",
            "Epoch 32: Loss 6.191152522689663, Val Loss 2.8587652356363833, Val Accuracy 0.978021978021978, Precision 0.9478142171322806, Recall 0.96819528558659, F1 0.957413193920447, Cohen Kappa 0.9540392789454494, Accuracy 0.978021978021978\n",
            "Epoch 33: Loss 6.272348559024977, Val Loss 2.5892286835005507, Val Accuracy 0.9795918367346939, Precision 0.9621655637662214, Recall 0.9695531652053391, F1 0.965721604034062, Cohen Kappa 0.9571514871631682, Accuracy 0.9795918367346939\n",
            "Epoch 34: Loss 6.16825993231032, Val Loss 2.7286171540617943, Val Accuracy 0.9811616954474097, Precision 0.9689381837456864, Recall 0.9720600198861068, F1 0.9704855023091231, Cohen Kappa 0.9604978082329824, Accuracy 0.9811616954474097\n",
            "Epoch 35: Loss 6.149517106299754, Val Loss 3.043435947969556, Val Accuracy 0.9772370486656201, Precision 0.947947965821733, Recall 0.9666546144807014, F1 0.956678147132935, Cohen Kappa 0.9523045404022343, Accuracy 0.9772370486656201\n",
            "Epoch 36: Loss 5.990042214281857, Val Loss 2.8067441978491843, Val Accuracy 0.978806907378336, Precision 0.954542299980318, Recall 0.9691614691614691, F1 0.9615349583613626, Cohen Kappa 0.9556212674219231, Accuracy 0.978806907378336\n",
            "Epoch 37: Loss 6.008043186942814, Val Loss 2.932700278237462, Val Accuracy 0.9756671899529042, Precision 0.9379005907274701, Recall 0.9698926351100265, F1 0.9527896054894957, Cohen Kappa 0.9494308505870753, Accuracy 0.9756671899529042\n",
            "Epoch 38: Loss 6.192624315386638, Val Loss 2.467439808533527, Val Accuracy 0.9811616954474097, Precision 0.9689381837456864, Recall 0.9720600198861068, F1 0.9704855023091231, Cohen Kappa 0.9604978082329824, Accuracy 0.9811616954474097\n",
            "Epoch 39: Loss 5.936696756165475, Val Loss 2.7401783182285726, Val Accuracy 0.9772370486656201, Precision 0.9443905492566059, Recall 0.96780358954272, F1 0.9553447383803043, Cohen Kappa 0.9524451869833727, Accuracy 0.9772370486656201\n",
            "Epoch 40: Loss 5.754837202955969, Val Loss 2.732114572543651, Val Accuracy 0.978021978021978, Precision 0.9458377163478812, Recall 0.9720770938162243, F1 0.9580068882781827, Cohen Kappa 0.9541007821858744, Accuracy 0.978021978021978\n",
            "Epoch 41: Loss 5.756442748592235, Val Loss 2.9525469815707766, Val Accuracy 0.9756671899529042, Precision 0.9405770891902825, Recall 0.9652967348619522, F1 0.9519768937505003, Cohen Kappa 0.9491167516352753, Accuracy 0.9756671899529042\n",
            "Epoch 42: Loss 5.805564861337189, Val Loss 3.6641691084951162, Val Accuracy 0.9803767660910518, Precision 0.9586608718512366, Recall 0.9710938363112276, F1 0.9646756617179552, Cohen Kappa 0.9589212474527304, Accuracy 0.9803767660910518\n",
            "Epoch 43: Loss 5.92138407897437, Val Loss 2.77999305492267, Val Accuracy 0.9819466248037677, Precision 0.9730262034609861, Recall 0.9730262034609861, F1 0.9730262034609861, Cohen Kappa 0.9621306699958385, Accuracy 0.9819466248037677\n",
            "Epoch 44: Loss 5.77106529759476, Val Loss 3.4858025410212576, Val Accuracy 0.9819466248037677, Precision 0.9693841102269648, Recall 0.9736006909919954, F1 0.9714783464613181, Cohen Kappa 0.9621931629776336, Accuracy 0.9819466248037677\n",
            "Epoch 45: Loss 6.128098393732216, Val Loss 3.7646543476730585, Val Accuracy 0.9811616954474097, Precision 0.9653976972055786, Recall 0.9726345074171162, F1 0.968964931780821, Cohen Kappa 0.9605629733578224, Accuracy 0.9811616954474097\n",
            "Epoch 46: Loss 5.749200964753982, Val Loss 2.9699671366252005, Val Accuracy 0.9772370486656201, Precision 0.9443651532444545, Recall 0.9672291020117108, F1 0.9550361821553665, Cohen Kappa 0.9524141945987161, Accuracy 0.9772370486656201\n",
            "Epoch 47: Loss 5.572098200238543, Val Loss 3.7210726253688335, Val Accuracy 0.978021978021978, Precision 0.9504198126343111, Recall 0.9693442606486085, F1 0.9594509250604583, Cohen Kappa 0.9540833532847806, Accuracy 0.978021978021978\n",
            "Epoch 48: Loss 5.829226052737795, Val Loss 2.8266138499602675, Val Accuracy 0.9811616954474097, Precision 0.9599526413398981, Recall 0.9753673405847318, F1 0.9673450956437581, Cohen Kappa 0.9605779731229862, Accuracy 0.9811616954474097\n",
            "Epoch 49: Loss 5.789244517334737, Val Loss 2.7368239995557815, Val Accuracy 0.9811616954474097, Precision 0.9757260908017021, Recall 0.9681782116564724, F1 0.9718976573538729, Cohen Kappa 0.9604050659138588, Accuracy 0.9811616954474097\n",
            "Epoch 50: Loss 5.566703501390293, Val Loss 2.620388744864613, Val Accuracy 0.9795918367346939, Precision 0.9692400022435358, Recall 0.9607801781714826, F1 0.9648723374241782, Cohen Kappa 0.9572028626173645, Accuracy 0.9795918367346939\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['pr'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_PR_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_PR_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KojeuBSaF6Qf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-PR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4x49TImF6mV",
        "outputId": "d4341b2b-4891-4a85-e275-ee2974240e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>[[0.4263324, 0.50016683, 0.12181714, -0.637440...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>[[0.43026865, 0.46168235, 0.19841376, -0.63281...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1  CVE-2016-0003  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                                       layer_output  \n",
              "0    7.5         HIGH  [[0.4263324, 0.50016683, 0.12181714, -0.637440...  \n",
              "1    9.6     CRITICAL  [[0.43026865, 0.46168235, 0.19841376, -0.63281...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-UI', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVqxOzVUF6mV",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 5.228157526842551, Val Loss 1.01026207418181, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 2: Loss 2.3724308944219956, Val Loss 0.8815768322965596, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 3: Loss 2.4277027247298975, Val Loss 1.0500153863540618, Val Accuracy 0.989010989010989, Precision 0.9875008074413798, Recall 0.9884789644012946, F1 0.9879867339488594, Cohen Kappa 0.9759735326289019, Accuracy 0.989010989010989\n",
            "Epoch 4: Loss 2.112536989585351, Val Loss 1.031586404365953, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 5: Loss 2.04005143129325, Val Loss 1.607153946401013, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 6: Loss 1.9748928834824255, Val Loss 0.9070409363484941, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n",
            "Epoch 7: Loss 1.6485154442416388, Val Loss 1.2175889819491204, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 8: Loss 1.8010341043541302, Val Loss 1.0407608393288683, Val Accuracy 0.9913657770800628, Precision 0.9918041230126997, Recall 0.9892907227615966, F1 0.9905274648767941, Cohen Kappa 0.9810552498884728, Accuracy 0.9913657770800628\n",
            "Epoch 9: Loss 1.5121486759362597, Val Loss 1.1281914607534418, Val Accuracy 0.9913657770800628, Precision 0.9918041230126997, Recall 0.9892907227615966, F1 0.9905274648767941, Cohen Kappa 0.9810552498884728, Accuracy 0.9913657770800628\n",
            "Epoch 10: Loss 1.269219559557314, Val Loss 1.3365592442078196, Val Accuracy 0.9913657770800628, Precision 0.9918041230126997, Recall 0.9892907227615966, F1 0.9905274648767941, Cohen Kappa 0.9810552498884728, Accuracy 0.9913657770800628\n",
            "Epoch 11: Loss 1.1247724002602126, Val Loss 1.416416443252274, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n",
            "Epoch 12: Loss 0.9413311459670695, Val Loss 1.7748935488498319, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n",
            "Epoch 13: Loss 1.0136098386534513, Val Loss 1.6921175017778296, Val Accuracy 0.9897959183673469, Precision 0.9911297852474323, Recall 0.986564185544768, F1 0.9887820740767834, Cohen Kappa 0.9775653789990708, Accuracy 0.9897959183673469\n",
            "Epoch 14: Loss 1.437177328745065, Val Loss 1.6348762050329242, Val Accuracy 0.9913657770800628, Precision 0.9918041230126997, Recall 0.9892907227615966, F1 0.9905274648767941, Cohen Kappa 0.9810552498884728, Accuracy 0.9913657770800628\n",
            "Epoch 15: Loss 0.7808511713840289, Val Loss 1.3209940359638495, Val Accuracy 0.9897959183673469, Precision 0.990077391198276, Recall 0.9875728155339806, F1 0.9888051857634841, Cohen Kappa 0.9776107498681952, Accuracy 0.9897959183673469\n",
            "Epoch 16: Loss 0.41337067039836484, Val Loss 1.6355403433967695, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 17: Loss 0.6773092241671748, Val Loss 1.2228299358139338, Val Accuracy 0.989010989010989, Precision 0.9894713991099533, Recall 0.9864617044228694, F1 0.987937857921546, Cohen Kappa 0.9758763031611294, Accuracy 0.989010989010989\n",
            "Epoch 18: Loss 0.4724321093968058, Val Loss 1.5509644226583532, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 19: Loss 0.5198909627507078, Val Loss 1.3312713140285268, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n",
            "Epoch 20: Loss 0.33023483120119224, Val Loss 1.9794404070581209, Val Accuracy 0.9913657770800628, Precision 0.9923275012020112, Recall 0.9887864077669903, F1 0.99051772260245, Cohen Kappa 0.9810360739503804, Accuracy 0.9913657770800628\n",
            "Epoch 21: Loss 0.31373493283547305, Val Loss 2.032374047121948, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 22: Loss 0.31945327955090264, Val Loss 2.3283654741536566, Val Accuracy 0.9905808477237049, Precision 0.9906847771928684, Recall 0.9886839266450917, F1 0.9896716101694916, Cohen Kappa 0.9793434436241393, Accuracy 0.9905808477237049\n",
            "Epoch 23: Loss 0.22550628088075886, Val Loss 2.366383652493937, Val Accuracy 0.9858712715855573, Precision 0.9827441347718127, Recall 0.9865560949298813, F1 0.9846003008488234, Cohen Kappa 0.9692019253497217, Accuracy 0.9858712715855573\n",
            "Epoch 24: Loss 0.17222915351707968, Val Loss 2.499758336030311, Val Accuracy 0.9874411302982732, Precision 0.9887971441028995, Recall 0.983735167206041, F1 0.9861861454846099, Cohen Kappa 0.9723741631203752, Accuracy 0.9874411302982732\n",
            "Epoch 25: Loss 0.6030840236007453, Val Loss 2.0290946599655797, Val Accuracy 0.9921507064364207, Precision 0.9924097181603517, Recall 0.9904018338727076, F1 0.9913930084745763, Cohen Kappa 0.9827862030201161, Accuracy 0.9921507064364207\n",
            "Epoch 26: Loss 0.22134421580549102, Val Loss 2.0850400969612934, Val Accuracy 0.9866562009419152, Precision 0.9838109216351651, Recall 0.9871628910463862, F1 0.9854486769905946, Cohen Kappa 0.9708983120537262, Accuracy 0.9866562009419152\n",
            "Epoch 27: Loss 0.19165490115213224, Val Loss 2.260487732680687, Val Accuracy 0.9897959183673469, Precision 0.9905971483132454, Recall 0.9870685005393742, F1 0.9887936721665318, Cohen Kappa 0.9775880873959041, Accuracy 0.9897959183673469\n",
            "Epoch 28: Loss 0.07420689113246226, Val Loss 2.7267115768365215, Val Accuracy 0.9905808477237049, Precision 0.9911999348746336, Recall 0.9881796116504854, F1 0.9896610210756109, Cohen Kappa 0.9793225455666823, Accuracy 0.9905808477237049\n",
            "Epoch 29: Loss 0.04308021331040379, Val Loss 3.0108124634351725, Val Accuracy 0.9897959183673469, Precision 0.9905971483132454, Recall 0.9870685005393742, F1 0.9887936721665318, Cohen Kappa 0.9775880873959041, Accuracy 0.9897959183673469\n",
            "Epoch 30: Loss 0.10506032075669403, Val Loss 2.9945762351994745, Val Accuracy 0.9897959183673469, Precision 0.990077391198276, Recall 0.9875728155339806, F1 0.9888051857634841, Cohen Kappa 0.9776107498681952, Accuracy 0.9897959183673469\n",
            "Epoch 31: Loss 0.25477325538974327, Val Loss 1.9502586758831058, Val Accuracy 0.9882260596546311, Precision 0.9868780864987485, Recall 0.9873678532901834, F1 0.9871221815873479, Cohen Kappa 0.9742443805308542, Accuracy 0.9882260596546311\n",
            "Epoch 32: Loss 0.060993279707000525, Val Loss 2.3557139620464795, Val Accuracy 0.989010989010989, Precision 0.9894713991099533, Recall 0.9864617044228694, F1 0.987937857921546, Cohen Kappa 0.9758763031611294, Accuracy 0.989010989010989\n",
            "Epoch 33: Loss 0.08766876204797436, Val Loss 2.6215399080846282, Val Accuracy 0.9866562009419152, Precision 0.9846993786181177, Recall 0.9861542610571736, F1 0.9854197591951179, Cohen Kappa 0.9708396950676027, Accuracy 0.9866562009419152\n",
            "Epoch 34: Loss 0.10654855459986345, Val Loss 3.114776914125841, Val Accuracy 0.9905808477237049, Precision 0.9901823547215496, Recall 0.989188241639698, F1 0.9896821218870216, Cohen Kappa 0.9793642994822178, Accuracy 0.9905808477237049\n",
            "Epoch 35: Loss 0.23802819195199243, Val Loss 3.2692708879283203, Val Accuracy 0.9913657770800628, Precision 0.9912935626195326, Recall 0.9897950377562028, F1 0.9905371360352531, Cohen Kappa 0.9810743870850991, Accuracy 0.9913657770800628\n",
            "Epoch 36: Loss 0.06972617295480354, Val Loss 2.5204128697231525, Val Accuracy 0.9850863422291993, Precision 0.982986612460441, Recall 0.9844363538295577, F1 0.9837044367474848, Cohen Kappa 0.9674090709579088, Accuracy 0.9850863422291993\n",
            "Epoch 37: Loss 0.15440821133021843, Val Loss 2.7929128440970503, Val Accuracy 0.9882260596546311, Precision 0.9878472363114029, Recall 0.9863592233009708, F1 0.987096094593527, Cohen Kappa 0.9741923460251352, Accuracy 0.9882260596546311\n",
            "Epoch 38: Loss 0.11230061304312308, Val Loss 2.6779464903244783, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n",
            "Epoch 39: Loss 0.3748150422357876, Val Loss 3.1513344073039953, Val Accuracy 0.9905808477237049, Precision 0.9901823547215496, Recall 0.989188241639698, F1 0.9896821218870216, Cohen Kappa 0.9793642994822178, Accuracy 0.9905808477237049\n",
            "Epoch 40: Loss 0.5524715630550769, Val Loss 1.7693754277775042, Val Accuracy 0.9866562009419152, Precision 0.986124073157338, Recall 0.9846413160733549, F1 0.985375573872664, Cohen Kappa 0.9707513254951531, Accuracy 0.9866562009419152\n",
            "Epoch 41: Loss 0.1424653678174863, Val Loss 2.322613545337859, Val Accuracy 0.9913657770800628, Precision 0.9918041230126997, Recall 0.9892907227615966, F1 0.9905274648767941, Cohen Kappa 0.9810552498884728, Accuracy 0.9913657770800628\n",
            "Epoch 42: Loss 0.05136352048898729, Val Loss 2.7507285358009703, Val Accuracy 0.9897959183673469, Precision 0.990077391198276, Recall 0.9875728155339806, F1 0.9888051857634841, Cohen Kappa 0.9776107498681952, Accuracy 0.9897959183673469\n",
            "Epoch 43: Loss 0.04236524243852813, Val Loss 2.5260289687346926, Val Accuracy 0.9897959183673469, Precision 0.990077391198276, Recall 0.9875728155339806, F1 0.9888051857634841, Cohen Kappa 0.9776107498681952, Accuracy 0.9897959183673469\n",
            "Epoch 44: Loss 0.043476972321653484, Val Loss 2.9336341648391553, Val Accuracy 0.989010989010989, Precision 0.9889598362253851, Recall 0.9869660194174756, F1 0.9879502118644068, Cohen Kappa 0.9759006842281626, Accuracy 0.989010989010989\n",
            "Epoch 45: Loss 0.050900493329544716, Val Loss 3.062520094356934, Val Accuracy 0.989010989010989, Precision 0.9894713991099533, Recall 0.9864617044228694, F1 0.987937857921546, Cohen Kappa 0.9758763031611294, Accuracy 0.989010989010989\n",
            "Epoch 46: Loss 0.04692734370219098, Val Loss 2.843710675415892, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n",
            "Epoch 47: Loss 0.0507529363383219, Val Loss 3.125560418185551, Val Accuracy 0.989010989010989, Precision 0.9889598362253851, Recall 0.9869660194174756, F1 0.9879502118644068, Cohen Kappa 0.9759006842281626, Accuracy 0.989010989010989\n",
            "Epoch 48: Loss 0.0669090603926919, Val Loss 3.3127008836807037, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n",
            "Epoch 49: Loss 0.03319632473273537, Val Loss 3.308707902201842, Val Accuracy 0.9897959183673469, Precision 0.990077391198276, Recall 0.9875728155339806, F1 0.9888051857634841, Cohen Kappa 0.9776107498681952, Accuracy 0.9897959183673469\n",
            "Epoch 50: Loss 0.04249020913922125, Val Loss 3.3550677179850155, Val Accuracy 0.9897959183673469, Precision 0.9895703994654678, Recall 0.9880771305285868, F1 0.98881661531439, Cohen Kappa 0.9776333665551171, Accuracy 0.9897959183673469\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['ui'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_UI_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_UI_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUVnj9HPF6mV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-UI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7bHjiZDF642",
        "outputId": "8a660796-0059-47fe-dd15-bf761eead6a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>[[-0.4219141, 0.16351242, -0.10466599, 0.43989...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>[[-0.22857915, 0.15007392, 0.5592636, 0.614801...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1  CVE-2016-0003  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                                       layer_output  \n",
              "0    7.5         HIGH  [[-0.4219141, 0.16351242, -0.10466599, 0.43989...  \n",
              "1    9.6     CRITICAL  [[-0.22857915, 0.15007392, 0.5592636, 0.614801...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-S', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wSdUhzOF642",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 4.355803234415362, Val Loss 1.2367863552644849, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 2: Loss 2.3384909312953823, Val Loss 1.947248605079949, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 3: Loss 2.0112096080265474, Val Loss 2.28043470159173, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 4: Loss 2.300373660043988, Val Loss 3.9154772087931633, Val Accuracy 0.9952904238618524, Precision 0.9933791959624241, Recall 0.9896678215696946, F1 0.9915120989233558, Cohen Kappa 0.9830242732461303, Accuracy 0.9952904238618524\n",
            "Epoch 5: Loss 2.1645051890736795, Val Loss 1.9045437397435308, Val Accuracy 0.9960753532182104, Precision 0.9938705894893934, Recall 0.9920152394100703, F1 0.9929400681610374, Cohen Kappa 0.9858801519712371, Accuracy 0.9960753532182104\n",
            "Epoch 6: Loss 2.1168589332155534, Val Loss 1.5239623440429568, Val Accuracy 0.9921507064364207, Precision 0.9933514339820666, Recall 0.9784019859022182, F1 0.9856908596715861, Cohen Kappa 0.9713837763532059, Accuracy 0.9921507064364207\n",
            "Epoch 7: Loss 2.0806912120606285, Val Loss 2.6067621912807226, Val Accuracy 0.9913657770800628, Precision 0.9928761224115814, Recall 0.9760545680618427, F1 0.9842296036469745, Cohen Kappa 0.9684620820336939, Accuracy 0.9913657770800628\n",
            "Epoch 8: Loss 1.9759156359068584, Val Loss 1.463829804211855, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 9: Loss 1.9388996853813296, Val Loss 1.3970245742239058, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 10: Loss 2.0101610363199143, Val Loss 0.7316236434271559, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 11: Loss 2.125641057587927, Val Loss 1.4686627369374037, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 12: Loss 1.7329207843504264, Val Loss 1.1906982334330678, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 13: Loss 1.7800616215954506, Val Loss 0.9602891276590526, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 14: Loss 1.8054431189120805, Val Loss 0.8555239087436348, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 15: Loss 1.7163599669775067, Val Loss 0.8512381028849632, Val Accuracy 0.9937205651491365, Precision 0.992398409596334, Recall 0.9849729858889436, F1 0.9886398594695331, Cohen Kappa 0.977280124121143, Accuracy 0.9937205651491365\n",
            "Epoch 16: Loss 1.6156869541700871, Val Loss 0.742998716654256, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 17: Loss 1.625369722833966, Val Loss 0.6473880292614922, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 18: Loss 1.5728194253970287, Val Loss 1.6628972738981247, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 19: Loss 1.6261999445741822, Val Loss 0.7824949466157705, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 20: Loss 1.5322266609946382, Val Loss 0.9015239060390741, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 21: Loss 1.421258965103334, Val Loss 0.7334032852559176, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 22: Loss 1.5841706577739387, Val Loss 0.7385350209660828, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 23: Loss 1.621038051519463, Val Loss 1.4087454153923318, Val Accuracy 0.9968602825745683, Precision 0.9943626572504458, Recall 0.9943626572504458, F1 0.9943626572504458, Cohen Kappa 0.9887253145008916, Accuracy 0.9968602825745683\n",
            "Epoch 24: Loss 1.3306024066150712, Val Loss 0.8978084762347862, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 25: Loss 1.3708315575167944, Val Loss 4.134340241551399, Val Accuracy 0.8492935635792779, Precision 0.8839391513210568, Recall 0.5530481032598356, F1 0.5550802139037433, Cohen Kappa 0.163910555711268, Accuracy 0.8492935635792779\n",
            "Epoch 26: Loss 1.2759844712463746, Val Loss 1.0480042970157228, Val Accuracy 0.9960753532182104, Precision 0.9938705894893934, Recall 0.9920152394100703, F1 0.9929400681610374, Cohen Kappa 0.9858801519712371, Accuracy 0.9960753532182104\n",
            "Epoch 27: Loss 1.052467305051323, Val Loss 4.911435325338971, Val Accuracy 0.8328100470957613, Precision 0.9164050235478807, Recall 0.5, F1 0.454389721627409, Cohen Kappa 0.0, Accuracy 0.8328100470957613\n",
            "Epoch 28: Loss 1.2142611584040424, Val Loss 0.7190130483359098, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 29: Loss 1.1960526959624076, Val Loss 0.6148009025346255, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 30: Loss 0.866889199887737, Val Loss 0.7102070263936184, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 31: Loss 0.9495792126861033, Val Loss 0.7718539504130604, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 32: Loss 0.8454181193508248, Val Loss 0.8999571481326711, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 33: Loss 1.1242877314816724, Val Loss 0.6780690525920363, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 34: Loss 0.8714137731813025, Val Loss 0.7328127839136869, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 35: Loss 0.7645130221562795, Val Loss 0.7097300938330591, Val Accuracy 0.9945054945054945, Precision 0.9874807463418049, Recall 0.9929488966472413, F1 0.9901897693308737, Cohen Kappa 0.980379732910919, Accuracy 0.9945054945054945\n",
            "Epoch 36: Loss 0.8117716087735971, Val Loss 1.1368899585213512, Val Accuracy 0.9913657770800628, Precision 0.9785966879420389, Recall 0.9910638825096352, F1 0.9846974486648212, Cohen Kappa 0.9693965347810326, Accuracy 0.9913657770800628\n",
            "Epoch 37: Loss 0.6655710633059755, Val Loss 0.8943256915663369, Val Accuracy 0.9905808477237049, Precision 0.9866747534649685, Recall 0.9793356431393893, F1 0.9829597892042998, Cohen Kappa 0.9659201861817144, Accuracy 0.9905808477237049\n",
            "Epoch 38: Loss 0.7943335085369654, Val Loss 0.7701130932546221, Val Accuracy 0.9937205651491365, Precision 0.9852290414136173, Recall 0.9924776431128397, F1 0.9888091002920703, Cohen Kappa 0.9776185937836259, Accuracy 0.9937205651491365\n",
            "Epoch 39: Loss 0.8304592770165868, Val Loss 0.6403788657626137, Val Accuracy 0.9952904238618524, Precision 0.9933791959624241, Recall 0.9896678215696946, F1 0.9915120989233558, Cohen Kappa 0.9830242732461303, Accuracy 0.9952904238618524\n",
            "Epoch 40: Loss 0.8345255649329602, Val Loss 0.6954573061084375, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 41: Loss 0.6683861139012208, Val Loss 0.6266635686988593, Val Accuracy 0.9968602825745683, Precision 0.9943626572504458, Recall 0.9943626572504458, F1 0.9943626572504458, Cohen Kappa 0.9887253145008916, Accuracy 0.9968602825745683\n",
            "Epoch 42: Loss 0.7500153736741879, Val Loss 1.0017993565124925, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 43: Loss 0.7432631577462416, Val Loss 0.9841479469614569, Val Accuracy 0.9952904238618524, Precision 0.9897533873553375, Recall 0.9934201501816428, F1 0.9915755598659848, Cohen Kappa 0.9831511940081379, Accuracy 0.9952904238618524\n",
            "Epoch 44: Loss 0.8173561150432533, Val Loss 0.7496940353885293, Val Accuracy 0.9952904238618524, Precision 0.9897533873553375, Recall 0.9934201501816428, F1 0.9915755598659848, Cohen Kappa 0.9831511940081379, Accuracy 0.9952904238618524\n",
            "Epoch 45: Loss 0.7834499301868618, Val Loss 0.7834669664589455, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 46: Loss 0.6231698785747568, Val Loss 0.735850508823205, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 47: Loss 0.7490541554702332, Val Loss 0.8471447768242797, Val Accuracy 0.9952904238618524, Precision 0.9897533873553375, Recall 0.9934201501816428, F1 0.9915755598659848, Cohen Kappa 0.9831511940081379, Accuracy 0.9952904238618524\n",
            "Epoch 48: Loss 0.6953580958607688, Val Loss 0.7114964112406597, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 49: Loss 0.859053063829819, Val Loss 0.6216709750005975, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n",
            "Epoch 50: Loss 0.7094766282137357, Val Loss 0.6381347993155941, Val Accuracy 0.9960753532182104, Precision 0.9920472579791924, Recall 0.9938914037160442, F1 0.9929665097657308, Cohen Kappa 0.9859330350636215, Accuracy 0.9960753532182104\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['s'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_S_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_S_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac8r4TVbF642"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLtoGTj4F7RN",
        "outputId": "4890d30c-e1a0-407e-8992-f29516e646a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>[[0.13871433, -1.8783141, 2.1884212, -0.310327...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>[[0.36604, -1.5219233, 1.9823239, -0.5423146, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1  CVE-2016-0003  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                                       layer_output  \n",
              "0    7.5         HIGH  [[0.13871433, -1.8783141, 2.1884212, -0.310327...  \n",
              "1    9.6     CRITICAL  [[0.36604, -1.5219233, 1.9823239, -0.5423146, ...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-I', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wj6gaCgF7RN",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 14.31390502557042, Val Loss 1.5683564390055835, Val Accuracy 0.989010989010989, Precision 0.9889647957644438, Recall 0.9886277346482738, F1 0.9887601419857192, Cohen Kappa 0.9819398921213336, Accuracy 0.989010989010989\n",
            "Epoch 2: Loss 5.636504236084875, Val Loss 1.2858061383012682, Val Accuracy 0.9905808477237049, Precision 0.9920146230450152, Recall 0.9883405159239561, F1 0.9901369367946539, Cohen Kappa 0.9844879596005102, Accuracy 0.9905808477237049\n",
            "Epoch 3: Loss 4.8750335229124175, Val Loss 1.1795359345851466, Val Accuracy 0.989010989010989, Precision 0.9904867702753734, Recall 0.9865338311904422, F1 0.9884818204465836, Cohen Kappa 0.981894113658189, Accuracy 0.989010989010989\n",
            "Epoch 4: Loss 4.581630380635033, Val Loss 1.538309556315653, Val Accuracy 0.9866562009419152, Precision 0.988011251533088, Recall 0.984461067981607, F1 0.9861352232689503, Cohen Kappa 0.9780386478426505, Accuracy 0.9866562009419152\n",
            "Epoch 5: Loss 3.997776687378064, Val Loss 1.2561500965966843, Val Accuracy 0.9866562009419152, Precision 0.9907444333665669, Recall 0.9826175363883963, F1 0.9865416262586604, Cohen Kappa 0.9779480193130469, Accuracy 0.9866562009419152\n",
            "Epoch 6: Loss 3.0730348357537878, Val Loss 1.1934634592980728, Val Accuracy 0.989010989010989, Precision 0.9866287244344546, Recall 0.9900009169264625, F1 0.988295038270428, Cohen Kappa 0.9819648377027514, Accuracy 0.989010989010989\n",
            "Epoch 7: Loss 2.363529613110586, Val Loss 1.2078123021237843, Val Accuracy 0.9897959183673469, Precision 0.9905907748600327, Recall 0.9883248093132561, F1 0.9894433969803541, Cohen Kappa 0.9832047305019415, Accuracy 0.9897959183673469\n",
            "Epoch 8: Loss 2.3118197349176626, Val Loss 1.3444015384302475, Val Accuracy 0.989010989010989, Precision 0.9894823766364551, Recall 0.9891132811704058, F1 0.9892617086771823, Cohen Kappa 0.9819398921213336, Accuracy 0.989010989010989\n",
            "Epoch 9: Loss 2.1418897642724914, Val Loss 1.206172154925298, Val Accuracy 0.9874411302982732, Precision 0.9883002614458679, Recall 0.985531324924778, F1 0.9868894104188222, Cohen Kappa 0.9793261945958446, Accuracy 0.9874411302982732\n",
            "Epoch 10: Loss 1.5847509358682146, Val Loss 1.5996681864489801, Val Accuracy 0.9882260596546311, Precision 0.9875590427704019, Recall 0.9886120280375735, F1 0.9880662240117198, Cohen Kappa 0.9806607329895916, Accuracy 0.9882260596546311\n",
            "Epoch 11: Loss 1.2856130119380396, Val Loss 1.5486051331427007, Val Accuracy 0.9850863422291993, Precision 0.9848898534148285, Recall 0.983223387058432, F1 0.9840511066089114, Cohen Kappa 0.9754521216989006, Accuracy 0.9850863422291993\n",
            "Epoch 12: Loss 0.9306740192732832, Val Loss 1.6206382806412876, Val Accuracy 0.989010989010989, Precision 0.9883167806360578, Recall 0.9887111919364807, F1 0.9885131964744689, Cohen Kappa 0.9819361425015141, Accuracy 0.989010989010989\n",
            "Epoch 13: Loss 0.7785856145837897, Val Loss 1.6263944600395916, Val Accuracy 0.9905808477237049, Precision 0.990594227251029, Recall 0.989713698202145, F1 0.9901523384759433, Cohen Kappa 0.9845053792320595, Accuracy 0.9905808477237049\n",
            "Epoch 14: Loss 2.2518148284957533, Val Loss 1.450499204078369, Val Accuracy 0.9882260596546311, Precision 0.9860991525019985, Recall 0.9886120280375735, F1 0.9873445364780489, Cohen Kappa 0.9806683041115513, Accuracy 0.9882260596546311\n",
            "Epoch 15: Loss 0.7652956873971561, Val Loss 1.8542489749906963, Val Accuracy 0.9874411302982732, Precision 0.9866774473783462, Recall 0.9872231391486848, F1 0.9869201990350355, Cohen Kappa 0.9793687551618597, Accuracy 0.9874411302982732\n",
            "Epoch 16: Loss 0.3911153444291813, Val Loss 1.9416134518164654, Val Accuracy 0.9874411302982732, Precision 0.9865269068960129, Recall 0.9868210499147598, F1 0.986666416100392, Cohen Kappa 0.9793590824998759, Accuracy 0.9874411302982732\n",
            "Epoch 17: Loss 0.23889319682621135, Val Loss 2.0628515440657793, Val Accuracy 0.9897959183673469, Precision 0.9905907748600327, Recall 0.9883248093132561, F1 0.9894433969803541, Cohen Kappa 0.9832047305019415, Accuracy 0.9897959183673469\n",
            "Epoch 18: Loss 0.15871384224215035, Val Loss 2.1562835843205903, Val Accuracy 0.9882260596546311, Precision 0.9884336081308168, Recall 0.9882099388036488, F1 0.9883057079166456, Cohen Kappa 0.9806466117898694, Accuracy 0.9882260596546311\n",
            "Epoch 19: Loss 1.0492275095007813, Val Loss 1.8753411715997572, Val Accuracy 0.9874411302982732, Precision 0.988691849945547, Recall 0.9846436891687212, F1 0.986627808522916, Cohen Kappa 0.9793110657988087, Accuracy 0.9874411302982732\n",
            "Epoch 20: Loss 0.7192791267711414, Val Loss 1.6899105571555992, Val Accuracy 0.9858712715855573, Precision 0.9858940462201332, Recall 0.9854999117033776, F1 0.9856961903480345, Cohen Kappa 0.976761107181438, Accuracy 0.9858712715855573\n",
            "Epoch 21: Loss 0.5615262337972808, Val Loss 2.072900398096408, Val Accuracy 0.9866562009419152, Precision 0.9865227844791651, Recall 0.9868053433040597, F1 0.986656511406208, Cohen Kappa 0.9780690251561182, Accuracy 0.9866562009419152\n",
            "Epoch 22: Loss 0.9241053536314894, Val Loss 2.2419565655627594, Val Accuracy 0.9874411302982732, Precision 0.9898371145109718, Recall 0.9838395107008715, F1 0.9867746723516094, Cohen Kappa 0.9792764234750624, Accuracy 0.9874411302982732\n",
            "Epoch 23: Loss 0.341617432332896, Val Loss 1.9738012543386958, Val Accuracy 0.9866562009419152, Precision 0.9860246686966998, Recall 0.9868053433040597, F1 0.9864118636709, Cohen Kappa 0.9780718895352958, Accuracy 0.9866562009419152\n",
            "Epoch 24: Loss 0.07757594736681028, Val Loss 2.174953878259373, Val Accuracy 0.9882260596546311, Precision 0.9878078495697237, Recall 0.9878078495697237, F1 0.9878078495697237, Cohen Kappa 0.9806400632161201, Accuracy 0.9882260596546311\n",
            "Epoch 25: Loss 0.18591364022648804, Val Loss 2.4778192178948757, Val Accuracy 0.9858712715855573, Precision 0.9858359457356691, Recall 0.9853329971269638, F1 0.9855206123144934, Cohen Kappa 0.9767837871219469, Accuracy 0.9858712715855573\n",
            "Epoch 26: Loss 0.56695938728501, Val Loss 1.9025875130264467, Val Accuracy 0.9882260596546311, Precision 0.9886209257298119, Recall 0.9868367565254599, F1 0.987662625067561, Cohen Kappa 0.9806390236637532, Accuracy 0.9882260596546311\n",
            "Epoch 27: Loss 0.9615211038627081, Val Loss 1.9879398858156492, Val Accuracy 0.9874411302982732, Precision 0.9870402112915979, Recall 0.9877086856708166, F1 0.9873617957869079, Cohen Kappa 0.9793652673637367, Accuracy 0.9874411302982732\n",
            "Epoch 28: Loss 0.13119206864269017, Val Loss 2.0142918009131563, Val Accuracy 0.9882260596546311, Precision 0.9873309321849125, Recall 0.987405760335799, F1 0.9873643121711752, Cohen Kappa 0.9806367872670918, Accuracy 0.9882260596546311\n",
            "Epoch 29: Loss 0.03268896592007309, Val Loss 2.1695885775639, Val Accuracy 0.9874411302982732, Precision 0.9869138717030284, Recall 0.9873065964368918, F1 0.9871094461940414, Cohen Kappa 0.9793555914303018, Accuracy 0.9874411302982732\n",
            "Epoch 30: Loss 0.03491853447734172, Val Loss 2.2776224817193906, Val Accuracy 0.9874411302982732, Precision 0.9869138717030284, Recall 0.9873065964368918, F1 0.9871094461940414, Cohen Kappa 0.9793555914303018, Accuracy 0.9874411302982732\n",
            "Epoch 31: Loss 0.030508727500182076, Val Loss 2.4813012544416893, Val Accuracy 0.989010989010989, Precision 0.9891903843837714, Recall 0.9883091027025559, F1 0.9887481195752518, Cohen Kappa 0.9819229424374027, Accuracy 0.989010989010989\n",
            "Epoch 32: Loss 0.17386192120262933, Val Loss 2.190438456503216, Val Accuracy 0.9882260596546311, Precision 0.9879216070354828, Recall 0.9882099388036488, F1 0.9880582045485479, Cohen Kappa 0.9806491398436337, Accuracy 0.9882260596546311\n",
            "Epoch 33: Loss 0.058335737912557306, Val Loss 2.9864034517470373, Val Accuracy 0.9858712715855573, Precision 0.9838102431944075, Recall 0.9867061794051525, F1 0.9852424988762741, Cohen Kappa 0.976808909132832, Accuracy 0.9858712715855573\n",
            "Epoch 34: Loss 0.36990085105435355, Val Loss 3.0464506799051065, Val Accuracy 0.9858712715855573, Precision 0.9837281627823552, Recall 0.9863040901712274, F1 0.9850018241937121, Cohen Kappa 0.9767980452565601, Accuracy 0.9858712715855573\n",
            "Epoch 35: Loss 0.14273080791932813, Val Loss 2.6976145888986025, Val Accuracy 0.9882260596546311, Precision 0.9874130158093041, Recall 0.9873223030475918, F1 0.9873636389868947, Cohen Kappa 0.9806433380568585, Accuracy 0.9882260596546311\n",
            "Epoch 36: Loss 0.018248109173853777, Val Loss 2.762514389348894, Val Accuracy 0.9882260596546311, Precision 0.9874259065019331, Recall 0.9882099388036488, F1 0.9878147726039291, Cohen Kappa 0.9806516672370257, Accuracy 0.9882260596546311\n",
            "Epoch 37: Loss 0.01297428378258303, Val Loss 2.878293819122291, Val Accuracy 0.9874411302982732, Precision 0.9860555129264168, Recall 0.9877086856708166, F1 0.9868765931313029, Cohen Kappa 0.9793706552023212, Accuracy 0.9874411302982732\n",
            "Epoch 38: Loss 0.01878162715782139, Val Loss 2.8582412832520845, Val Accuracy 0.989010989010989, Precision 0.9900848024372509, Recall 0.987421466946499, F1 0.9887384153652056, Cohen Kappa 0.9819073558426277, Accuracy 0.989010989010989\n",
            "Epoch 39: Loss 0.05795351590069142, Val Loss 2.97480760160591, Val Accuracy 0.9874411302982732, Precision 0.9881793306803429, Recall 0.985531324924778, F1 0.9868406662948143, Cohen Kappa 0.9793226923915744, Accuracy 0.9874411302982732\n",
            "Epoch 40: Loss 0.11322510817780085, Val Loss 2.7848002959178615, Val Accuracy 0.9874411302982732, Precision 0.9881010981080588, Recall 0.98601687144691, F1 0.987049106778893, Cohen Kappa 0.979321895317095, Accuracy 0.9874411302982732\n",
            "Epoch 41: Loss 0.8713001584635842, Val Loss 2.3521799116545026, Val Accuracy 0.9882260596546311, Precision 0.9869464007857954, Recall 0.9882099388036488, F1 0.9875753990052863, Cohen Kappa 0.9806541939703041, Accuracy 0.9882260596546311\n",
            "Epoch 42: Loss 0.09249538446518812, Val Loss 2.442528042765673, Val Accuracy 0.9882260596546311, Precision 0.9873355362065636, Recall 0.9878078495697237, F1 0.9875696669098083, Cohen Kappa 0.9806425929808887, Accuracy 0.9882260596546311\n",
            "Epoch 43: Loss 0.08692561392877529, Val Loss 2.63216148574773, Val Accuracy 0.9874411302982732, Precision 0.9864473163945758, Recall 0.9877921429590236, F1 0.9871132707900044, Cohen Kappa 0.9793609843222861, Accuracy 0.9874411302982732\n",
            "Epoch 44: Loss 0.015493434747689605, Val Loss 2.4256556001139415, Val Accuracy 0.989010989010989, Precision 0.9883167806360578, Recall 0.9887111919364807, F1 0.9885131964744689, Cohen Kappa 0.9819361425015141, Accuracy 0.989010989010989\n",
            "Epoch 45: Loss 0.04522571692478827, Val Loss 2.4412404375760843, Val Accuracy 0.989010989010989, Precision 0.9883167806360578, Recall 0.9887111919364807, F1 0.9885131964744689, Cohen Kappa 0.9819361425015141, Accuracy 0.989010989010989\n",
            "Epoch 46: Loss 0.13312803767209402, Val Loss 2.7184926668888494, Val Accuracy 0.9882260596546311, Precision 0.9874130158093041, Recall 0.9873223030475918, F1 0.9873636389868947, Cohen Kappa 0.9806433380568585, Accuracy 0.9882260596546311\n",
            "Epoch 47: Loss 0.015955465107410083, Val Loss 2.6516259102060644, Val Accuracy 0.9882260596546311, Precision 0.9869464007857954, Recall 0.9882099388036488, F1 0.9875753990052863, Cohen Kappa 0.9806541939703041, Accuracy 0.9882260596546311\n",
            "Epoch 48: Loss 0.05268433337054823, Val Loss 2.8581266367435205, Val Accuracy 0.9874411302982732, Precision 0.9860555129264168, Recall 0.9877086856708166, F1 0.9868765931313029, Cohen Kappa 0.9793706552023212, Accuracy 0.9874411302982732\n",
            "Epoch 49: Loss 0.0031548487574690753, Val Loss 2.5767145395325315, Val Accuracy 0.9874411302982732, Precision 0.9860555129264168, Recall 0.9877086856708166, F1 0.9868765931313029, Cohen Kappa 0.9793706552023212, Accuracy 0.9874411302982732\n",
            "Epoch 50: Loss 0.004035838412658865, Val Loss 2.648752613157427, Val Accuracy 0.989010989010989, Precision 0.9878420788823862, Recall 0.9887111919364807, F1 0.9882750287419121, Cohen Kappa 0.9819385021999666, Accuracy 0.989010989010989\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['i'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_I_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_I_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOO1NRNMF7Rc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-I')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsuosrVAF7mT",
        "outputId": "0bb54170-5786-446b-9eb1-2adc65d986b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>[[-0.0075685373, -0.56675094, 1.6247126, -0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>[[0.21460105, -0.14746664, 1.4321923, 0.144626...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1  CVE-2016-0003  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                                       layer_output  \n",
              "0    7.5         HIGH  [[-0.0075685373, -0.56675094, 1.6247126, -0.01...  \n",
              "1    9.6     CRITICAL  [[0.21460105, -0.14746664, 1.4321923, 0.144626...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-C', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZTwOBJwF7mT",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 15.326360169856343, Val Loss 1.175851786043495, Val Accuracy 0.9897959183673469, Precision 0.9895048565052252, Recall 0.9867288777155193, F1 0.9880932144837496, Cohen Kappa 0.982064713010501, Accuracy 0.9897959183673469\n",
            "Epoch 2: Loss 7.4538422705372795, Val Loss 1.2537511495756917, Val Accuracy 0.9866562009419152, Precision 0.984063701348476, Recall 0.9827627813168004, F1 0.9833900090909437, Cohen Kappa 0.9765618236282098, Accuracy 0.9866562009419152\n",
            "Epoch 3: Loss 5.765794162696693, Val Loss 1.3836489426903427, Val Accuracy 0.9858712715855573, Precision 0.9830836369317738, Recall 0.9830836369317738, F1 0.9830836369317738, Cohen Kappa 0.9752072012852642, Accuracy 0.9858712715855573\n",
            "Epoch 4: Loss 4.792856049607508, Val Loss 1.3141839418094605, Val Accuracy 0.9858712715855573, Precision 0.9844923355162406, Recall 0.9831995369679927, F1 0.9838226847572642, Cohen Kappa 0.9751831073710456, Accuracy 0.9858712715855573\n",
            "Epoch 5: Loss 3.58645472174976, Val Loss 1.1476331159065012, Val Accuracy 0.9874411302982732, Precision 0.9858250205121561, Recall 0.9861584677333447, F1 0.985962652518492, Cohen Kappa 0.9779715069049773, Accuracy 0.9874411302982732\n",
            "Epoch 6: Loss 2.8584242319775512, Val Loss 1.58935178630054, Val Accuracy 0.9827315541601256, Precision 0.9801995093408794, Recall 0.9796522288741647, F1 0.97991080969286, Cohen Kappa 0.9696837605635783, Accuracy 0.9827315541601256\n",
            "Epoch 7: Loss 2.6735027936301776, Val Loss 1.2231197802029783, Val Accuracy 0.9874411302982732, Precision 0.9840845697258754, Recall 0.9870408561831107, F1 0.9855432751625296, Cohen Kappa 0.978006944039843, Accuracy 0.9874411302982732\n",
            "Epoch 8: Loss 1.289596503984285, Val Loss 1.3711579753944534, Val Accuracy 0.9874411302982732, Precision 0.9874502734749765, Recall 0.9835113023840467, F1 0.9854033280362394, Cohen Kappa 0.9779127649568853, Accuracy 0.9874411302982732\n",
            "Epoch 9: Loss 0.4242871678470692, Val Loss 1.5859422391404223, Val Accuracy 0.9819466248037677, Precision 0.9774433182548253, Recall 0.9775577192122774, F1 0.9774981635985335, Cohen Kappa 0.9683211347395051, Accuracy 0.9819466248037677\n",
            "Epoch 10: Loss 0.46716150790598476, Val Loss 1.9118984989308956, Val Accuracy 0.9858712715855573, Precision 0.9853043319669718, Recall 0.9805523716186947, F1 0.9829003575208635, Cohen Kappa 0.9751296011105568, Accuracy 0.9858712715855573\n",
            "Epoch 11: Loss 1.1014136712738036, Val Loss 1.9029193840397056, Val Accuracy 0.9843014128728415, Precision 0.9784702907268966, Recall 0.9852583249888148, F1 0.9817956660426829, Cohen Kappa 0.9725800671723787, Accuracy 0.9843014128728415\n",
            "Epoch 12: Loss 1.1741395708568234, Val Loss 1.72098123444448, Val Accuracy 0.9835164835164835, Precision 0.9817002810198979, Recall 0.9790995731867539, F1 0.9803868241466053, Cohen Kappa 0.9710283662983037, Accuracy 0.9835164835164835\n",
            "Epoch 13: Loss 0.6244575189793977, Val Loss 2.2850688494454516, Val Accuracy 0.9850863422291993, Precision 0.9840760167438933, Recall 0.9791084503341358, F1 0.9815616329264886, Cohen Kappa 0.973746545598105, Accuracy 0.9850863422291993\n",
            "Epoch 14: Loss 0.7284501214589909, Val Loss 1.855119767777751, Val Accuracy 0.9843014128728415, Precision 0.9805079149711234, Recall 0.9828429597119542, F1 0.9816685373648785, Cohen Kappa 0.9724953556227459, Accuracy 0.9843014128728415\n",
            "Epoch 15: Loss 0.2684527202472964, Val Loss 2.08115613973996, Val Accuracy 0.9843014128728415, Precision 0.9795440213048415, Recall 0.982076471298407, F1 0.9807974528196288, Cohen Kappa 0.9724967806769376, Accuracy 0.9843014128728415\n",
            "Epoch 16: Loss 0.24182913199223321, Val Loss 2.1733017741031517, Val Accuracy 0.9843014128728415, Precision 0.982875881771272, Recall 0.9786628175355618, F1 0.9807436198536582, Cohen Kappa 0.9723789546713497, Accuracy 0.9843014128728415\n",
            "Epoch 17: Loss 1.1292418733953866, Val Loss 2.1143447791482686, Val Accuracy 0.9850863422291993, Precision 0.9809540233798684, Recall 0.9831726924743095, F1 0.9820524103867386, Cohen Kappa 0.9738699108882568, Accuracy 0.9850863422291993\n",
            "Epoch 18: Loss 0.3298526820742893, Val Loss 2.4526933782500464, Val Accuracy 0.9850863422291993, Precision 0.9823061976746321, Recall 0.9803385388925582, F1 0.9812700264552218, Cohen Kappa 0.9737916563357041, Accuracy 0.9850863422291993\n",
            "Epoch 19: Loss 0.07771751818211214, Val Loss 2.4869671887215645, Val Accuracy 0.9874411302982732, Precision 0.984522673906473, Recall 0.9839749025289217, F1 0.9842336705175728, Cohen Kappa 0.9779518258644206, Accuracy 0.9874411302982732\n",
            "Epoch 20: Loss 0.019966121730746522, Val Loss 2.2371273739587707, Val Accuracy 0.9882260596546311, Precision 0.985823486740346, Recall 0.9850711237048242, F1 0.9854460697532774, Cohen Kappa 0.979328763522569, Accuracy 0.9882260596546311\n",
            "Epoch 21: Loss 0.09259273219684871, Val Loss 2.322888014047521, Val Accuracy 0.9858712715855573, Precision 0.9836057689277551, Recall 0.9815506601046793, F1 0.98254435695023, Cohen Kappa 0.975170397639607, Accuracy 0.9858712715855573\n",
            "Epoch 22: Loss 0.2130349329032839, Val Loss 3.0093294751181645, Val Accuracy 0.9850863422291993, Precision 0.9840753384437543, Recall 0.9792243503703547, F1 0.9816230033401889, Cohen Kappa 0.9737472289585223, Accuracy 0.9850863422291993\n",
            "Epoch 23: Loss 0.03611616925558536, Val Loss 3.0356328729133253, Val Accuracy 0.9850863422291993, Precision 0.9831224616073405, Recall 0.9801067388201204, F1 0.9815947540728417, Cohen Kappa 0.9737761821085223, Accuracy 0.9850863422291993\n",
            "Epoch 24: Loss 0.23307986766666744, Val Loss 3.2606331183469734, Val Accuracy 0.9850863422291993, Precision 0.985127749687921, Recall 0.9799908387839018, F1 0.9825198225281113, Cohen Kappa 0.9737458622021111, Accuracy 0.9850863422291993\n",
            "Epoch 25: Loss 1.4580999306985802, Val Loss 3.4266154575198016, Val Accuracy 0.9693877551020408, Precision 0.9584348270676059, Recall 0.9783242786430039, F1 0.9673363830866637, Cohen Kappa 0.9471205575936373, Accuracy 0.9693877551020408\n",
            "Epoch 26: Loss 0.21053573827121852, Val Loss 2.6847828647732968, Val Accuracy 0.9835164835164835, Precision 0.9831618117332402, Recall 0.9764524078374559, F1 0.9797460284856895, Cohen Kappa 0.9709517077842127, Accuracy 0.9835164835164835\n",
            "Epoch 27: Loss 0.15122649831141644, Val Loss 2.614682776612355, Val Accuracy 0.9882260596546311, Precision 0.9859358336367682, Recall 0.9850711237048242, F1 0.9855020268565924, Cohen Kappa 0.9793282268681128, Accuracy 0.9882260596546311\n",
            "Epoch 28: Loss 0.8338322134532135, Val Loss 3.274906434057982, Val Accuracy 0.9819466248037677, Precision 0.9797455190655601, Recall 0.9757929423127454, F1 0.9777506379050164, Cohen Kappa 0.9682374505844236, Accuracy 0.9819466248037677\n",
            "Epoch 29: Loss 0.44115061247612175, Val Loss 2.5690282868609415, Val Accuracy 0.9882260596546311, Precision 0.9855847745284384, Recall 0.9873705889454659, F1 0.9864263438800709, Cohen Kappa 0.9793693788034672, Accuracy 0.9882260596546311\n",
            "Epoch 30: Loss 0.09427595839758851, Val Loss 2.549828255982675, Val Accuracy 0.9850863422291993, Precision 0.9809012674072916, Recall 0.9817556156834338, F1 0.9813270050317332, Cohen Kappa 0.9738438780130164, Accuracy 0.9850863422291993\n",
            "Epoch 31: Loss 0.03761045101815341, Val Loss 2.4808185715553464, Val Accuracy 0.9850863422291993, Precision 0.9809012674072916, Recall 0.9817556156834338, F1 0.9813270050317332, Cohen Kappa 0.9738438780130164, Accuracy 0.9850863422291993\n",
            "Epoch 32: Loss 0.014546285329231523, Val Loss 2.6921825776615833, Val Accuracy 0.9843014128728415, Precision 0.979611524971124, Recall 0.9813099828848598, F1 0.9804550380453995, Cohen Kappa 0.9724820182733223, Accuracy 0.9843014128728415\n",
            "Epoch 33: Loss 0.008058623252985342, Val Loss 2.90603851900849, Val Accuracy 0.9850863422291993, Precision 0.9809012674072916, Recall 0.9817556156834338, F1 0.9813270050317332, Cohen Kappa 0.9738438780130164, Accuracy 0.9850863422291993\n",
            "Epoch 34: Loss 0.016972217980537607, Val Loss 2.846942622704077, Val Accuracy 0.9843014128728415, Precision 0.9804275944350939, Recall 0.9804275944350939, F1 0.9804275944350939, Cohen Kappa 0.9724524458725158, Accuracy 0.9843014128728415\n",
            "Epoch 35: Loss 0.008726401261018424, Val Loss 2.912383898438975, Val Accuracy 0.9843014128728415, Precision 0.9804275944350939, Recall 0.9804275944350939, F1 0.9804275944350939, Cohen Kappa 0.9724524458725158, Accuracy 0.9843014128728415\n",
            "Epoch 36: Loss 0.0024314664683444676, Val Loss 2.934718702641071, Val Accuracy 0.9850863422291993, Precision 0.9809003900584149, Recall 0.9816397156472151, F1 0.981268832977095, Cohen Kappa 0.973843199674958, Accuracy 0.9850863422291993\n",
            "Epoch 37: Loss 0.0022938844015278903, Val Loss 2.881709213037823, Val Accuracy 0.9850863422291993, Precision 0.9809012674072916, Recall 0.9817556156834338, F1 0.9813270050317332, Cohen Kappa 0.9738438780130164, Accuracy 0.9850863422291993\n",
            "Epoch 38: Loss 0.004200380939868964, Val Loss 3.1527211056987454, Val Accuracy 0.9827315541601256, Precision 0.9802092400464613, Recall 0.9770050635248667, F1 0.978595296025953, Cohen Kappa 0.9696340002123497, Accuracy 0.9827315541601256\n",
            "Epoch 39: Loss 0.0071105388775905, Val Loss 3.2013124320260182, Val Accuracy 0.9866562009419152, Precision 0.9850117014690829, Recall 0.9825309812443629, F1 0.9837637072762129, Cohen Kappa 0.9765473822360876, Accuracy 0.9866562009419152\n",
            "Epoch 40: Loss 0.001778425015766416, Val Loss 3.2014752083477127, Val Accuracy 0.9858712715855573, Precision 0.9814027695572531, Recall 0.9837342253091023, F1 0.9825615938507012, Cohen Kappa 0.9752458200604713, Accuracy 0.9858712715855573\n",
            "Epoch 41: Loss 0.0017081028957957045, Val Loss 3.2966212806886084, Val Accuracy 0.9858712715855573, Precision 0.9820853484457891, Recall 0.9820853484457891, F1 0.9820853484457891, Cohen Kappa 0.9752072012852642, Accuracy 0.9858712715855573\n",
            "Epoch 42: Loss 0.0016732595526933736, Val Loss 3.2063108687171518, Val Accuracy 0.9866562009419152, Precision 0.9842836060481939, Recall 0.9832974696579102, F1 0.983784087634838, Cohen Kappa 0.9765713822105633, Accuracy 0.9866562009419152\n",
            "Epoch 43: Loss 0.640984757947181, Val Loss 4.602154119412148, Val Accuracy 0.9772370486656201, Precision 0.9803071745095716, Recall 0.9663366498355952, F1 0.9729831501903994, Cohen Kappa 0.9596828403813249, Accuracy 0.9772370486656201\n",
            "Epoch 44: Loss 0.3976160346743356, Val Loss 3.0561742777632332, Val Accuracy 0.9835164835164835, Precision 0.979808798966974, Recall 0.9800978616727386, F1 0.9799320807443687, Cohen Kappa 0.9710773195764839, Accuracy 0.9835164835164835\n",
            "Epoch 45: Loss 0.09234613899676347, Val Loss 2.77309718240258, Val Accuracy 0.9850863422291993, Precision 0.983527830963134, Recall 0.9815238156109963, F1 0.9824998801343025, Cohen Kappa 0.9738003082571349, Accuracy 0.9850863422291993\n",
            "Epoch 46: Loss 0.020629322043014042, Val Loss 2.997646467605051, Val Accuracy 0.9866562009419152, Precision 0.9825105294747307, Recall 0.9844116581801138, F1 0.9834357384723877, Cohen Kappa 0.9766109280033867, Accuracy 0.9866562009419152\n",
            "Epoch 47: Loss 0.005879500281473327, Val Loss 2.904053810187264, Val Accuracy 0.9858712715855573, Precision 0.9828613374126469, Recall 0.982967736895555, F1 0.982912164693703, Cohen Kappa 0.9752078445787431, Accuracy 0.9858712715855573\n",
            "Epoch 48: Loss 0.004756013655063285, Val Loss 3.243354984586972, Val Accuracy 0.9858712715855573, Precision 0.9845515691510235, Recall 0.9812029599960229, F1 0.9828620495392727, Cohen Kappa 0.9751544450487658, Accuracy 0.9858712715855573\n",
            "Epoch 49: Loss 0.002566145979346679, Val Loss 3.100746812284136, Val Accuracy 0.9866562009419152, Precision 0.9850117014690829, Recall 0.9825309812443629, F1 0.9837637072762129, Cohen Kappa 0.9765473822360876, Accuracy 0.9866562009419152\n",
            "Epoch 50: Loss 0.0022776451473807136, Val Loss 2.976253317984156, Val Accuracy 0.9858712715855573, Precision 0.9836950527169505, Recall 0.9820853484457891, F1 0.9828872293035432, Cohen Kappa 0.975181173536975, Accuracy 0.9858712715855573\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['c'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_C_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_C_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aThTBpwyF7mT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-C')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajWFKv_nF74_",
        "outputId": "e764039c-c286-4e24-ea5b-4f9b8f64fe68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>vectorString</th>\n",
              "      <th>av</th>\n",
              "      <th>ac</th>\n",
              "      <th>pr</th>\n",
              "      <th>ui</th>\n",
              "      <th>s</th>\n",
              "      <th>c</th>\n",
              "      <th>i</th>\n",
              "      <th>a</th>\n",
              "      <th>score</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>formatted_description</th>\n",
              "      <th>layer_output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CVE-2016-0002</td>\n",
              "      <td>The Microsoft (1) VBScript 5.7 and 5.8 and (2)...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft VBScript and JS...</td>\n",
              "      <td>[[-0.7838036, -0.32860562, 1.4268495, 0.191125...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CVE-2016-0003</td>\n",
              "      <td>Microsoft Edge allows remote attackers to exec...</td>\n",
              "      <td>CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.6</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>MEMORY CORRUPTION in Microsoft Edge causes arb...</td>\n",
              "      <td>[[-0.36760885, -0.15255734, -0.22562566, 0.376...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID                                               text  \\\n",
              "0  CVE-2016-0002  The Microsoft (1) VBScript 5.7 and 5.8 and (2)...   \n",
              "1  CVE-2016-0003  Microsoft Edge allows remote attackers to exec...   \n",
              "\n",
              "                                   vectorString  av  ac  pr  ui  s  c  i  a  \\\n",
              "0  CVSS:3.0/AV:N/AC:H/PR:N/UI:R/S:U/C:H/I:H/A:H   0   1   2   0  1  0  0  0   \n",
              "1  CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H   0   0   2   0  0  0  0  0   \n",
              "\n",
              "   score baseSeverity                              formatted_description  \\\n",
              "0    7.5         HIGH  MEMORY CORRUPTION in Microsoft VBScript and JS...   \n",
              "1    9.6     CRITICAL  MEMORY CORRUPTION in Microsoft Edge causes arb...   \n",
              "\n",
              "                                        layer_output  \n",
              "0  [[-0.7838036, -0.32860562, 1.4268495, 0.191125...  \n",
              "1  [[-0.36760885, -0.15255734, -0.22562566, 0.376...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "########LOAD MODEL##################\n",
        "model = BertModel.from_pretrained('/home/leili/Vul/Bert/BertLLMFinetuned/bert-model-A', output_hidden_states=True).to(device)\n",
        "#model = model.half()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_process(texts, layer_index):\n",
        "\n",
        "    tokens = tokenizer(texts, add_special_tokens=True, max_length=120, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    layer_output = hidden_states[layer_index].detach().to('cpu')\n",
        "    return layer_output.numpy()\n",
        "\n",
        "batch_size = 100\n",
        "results = []\n",
        "\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch_texts = df['text'][i:i + batch_size].tolist()\n",
        "    batch_output = batch_process(batch_texts,12)###############################################################\n",
        "    results.append(batch_output)\n",
        "\n",
        "results = np.vstack(results)\n",
        "\n",
        "\n",
        "expected_shape = (len(df), 120, 768)\n",
        "if results.shape == expected_shape:\n",
        "    df['layer_output'] = list(results)\n",
        "else:\n",
        "    print(f\"Unexpected result shape: {results.shape}. Expected: {expected_shape}\")\n",
        "\n",
        "\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5_x_cMLF75O",
        "outputId": "03d1d203-ddef-42e5-eab8-3c8b8dc75d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using: cuda\n",
            "Let's use 2 GPUs!\n",
            "Epoch 1: Loss 39.8249675501138, Val Loss 7.896350160241127, Val Accuracy 0.9128728414442701, Precision 0.8146901871818258, Recall 0.6748139280524345, F1 0.6989630552383588, Cohen Kappa 0.8233656381502442, Accuracy 0.9128728414442701\n",
            "Epoch 2: Loss 32.07950909156352, Val Loss 8.541153380647302, Val Accuracy 0.9042386185243328, Precision 0.7819997845391446, Recall 0.6828728261291127, F1 0.7034163349519202, Cohen Kappa 0.8084035768084357, Accuracy 0.9042386185243328\n",
            "Epoch 3: Loss 29.632363910786808, Val Loss 7.851031696423888, Val Accuracy 0.9183673469387755, Precision 0.7662194955102865, Recall 0.7163259075882902, F1 0.7354905180462991, Cohen Kappa 0.8345173505990029, Accuracy 0.9183673469387755\n",
            "Epoch 4: Loss 27.541865947656333, Val Loss 7.870288650505245, Val Accuracy 0.9160125588697017, Precision 0.7357599806954983, Recall 0.7178246807406067, F1 0.7254869798772239, Cohen Kappa 0.8315766323975107, Accuracy 0.9160125588697017\n",
            "Epoch 5: Loss 25.415024245157838, Val Loss 8.942438308149576, Val Accuracy 0.9128728414442701, Precision 0.8064030521963557, Recall 0.7186304531999225, F1 0.7437369707363556, Cohen Kappa 0.8258238063214526, Accuracy 0.9128728414442701\n",
            "Epoch 6: Loss 24.472306131850928, Val Loss 7.569379729451612, Val Accuracy 0.9215070643642073, Precision 0.8288102301883525, Recall 0.7193534657339585, F1 0.7518579261461564, Cohen Kappa 0.8405682478024948, Accuracy 0.9215070643642073\n",
            "Epoch 7: Loss 21.653656895272434, Val Loss 8.44063953217119, Val Accuracy 0.9034536891679749, Precision 0.73102027175511, Recall 0.7791989249952166, F1 0.7496173685773319, Cohen Kappa 0.8086262421732551, Accuracy 0.9034536891679749\n",
            "Epoch 8: Loss 20.134241900406778, Val Loss 7.970576667226851, Val Accuracy 0.9073783359497645, Precision 0.7484271897069891, Recall 0.7061127871389492, F1 0.7235205171684772, Cohen Kappa 0.8111940720273793, Accuracy 0.9073783359497645\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Loss 17.855322983348742, Val Loss 8.334044075571, Val Accuracy 0.9128728414442701, Precision 0.8838900570846716, Recall 0.6727694850631097, F1 0.7025767353892354, Cohen Kappa 0.8222298765034797, Accuracy 0.9128728414442701\n",
            "Epoch 10: Loss 15.127599977888167, Val Loss 8.237061473540962, Val Accuracy 0.9183673469387755, Precision 0.8255000361907978, Recall 0.7181147952039494, F1 0.7495388250423792, Cohen Kappa 0.8347720034218815, Accuracy 0.9183673469387755\n",
            "Epoch 11: Loss 13.496782504371367, Val Loss 8.223570068366826, Val Accuracy 0.9136577708006279, Precision 0.7629968452093254, Recall 0.7260609215143125, F1 0.7407061860434117, Cohen Kappa 0.826565201410349, Accuracy 0.9136577708006279\n",
            "Epoch 12: Loss 10.524659434217028, Val Loss 8.608393465634435, Val Accuracy 0.9105180533751962, Precision 0.7484784107934673, Recall 0.7325819401003552, F1 0.7399238087087879, Cohen Kappa 0.8200712103530041, Accuracy 0.9105180533751962\n",
            "Epoch 13: Loss 9.041890254593454, Val Loss 9.449401167454198, Val Accuracy 0.9160125588697017, Precision 0.7976708667430318, Recall 0.7250732591093273, F1 0.7510442256817856, Cohen Kappa 0.8296719086972059, Accuracy 0.9160125588697017\n",
            "Epoch 14: Loss 6.979325367428828, Val Loss 10.766050159902079, Val Accuracy 0.9128728414442701, Precision 0.8120824255628177, Recall 0.7099415704952916, F1 0.7427103703712478, Cohen Kappa 0.8214992577931717, Accuracy 0.9128728414442701\n",
            "Epoch 15: Loss 6.023940200917423, Val Loss 10.70035014563473, Val Accuracy 0.9113029827315542, Precision 0.7775143476413703, Recall 0.7216819210723199, F1 0.7431785253286267, Cohen Kappa 0.8201967367085319, Accuracy 0.9113029827315542\n",
            "Epoch 16: Loss 4.4800488575710915, Val Loss 12.2719607478939, Val Accuracy 0.8924646781789639, Precision 0.7643631951612612, Recall 0.696267993829589, F1 0.7208711084342293, Cohen Kappa 0.780839084270058, Accuracy 0.8924646781789639\n",
            "Epoch 17: Loss 4.574047441885341, Val Loss 12.71183206202113, Val Accuracy 0.9113029827315542, Precision 0.7772100984167736, Recall 0.7211708103249886, F1 0.7427628823249197, Cohen Kappa 0.8201336110337176, Accuracy 0.9113029827315542\n",
            "Epoch 18: Loss 2.850632791800308, Val Loss 13.58368659997359, Val Accuracy 0.9034536891679749, Precision 0.8217230472185671, Recall 0.6984658697892124, F1 0.7297737736028592, Cohen Kappa 0.8050504598112982, Accuracy 0.9034536891679749\n",
            "Epoch 19: Loss 3.5307934162628953, Val Loss 12.809345464396756, Val Accuracy 0.9050235478806907, Precision 0.800262204693503, Recall 0.7169045816493113, F1 0.7456349206349207, Cohen Kappa 0.8071421243716487, Accuracy 0.9050235478806907\n",
            "Epoch 20: Loss 4.015610351874784, Val Loss 14.407179988105781, Val Accuracy 0.9113029827315542, Precision 0.75437416376281, Recall 0.7201485888303263, F1 0.7349678212298021, Cohen Kappa 0.8197162285699974, Accuracy 0.9113029827315542\n",
            "Epoch 21: Loss 3.213323396463238, Val Loss 14.39651536245583, Val Accuracy 0.9097331240188383, Precision 0.8676052637433135, Recall 0.6867946373915386, F1 0.7261674373901693, Cohen Kappa 0.8139709103375594, Accuracy 0.9097331240188383\n",
            "Epoch 22: Loss 2.9925379731721478, Val Loss 14.7049351031892, Val Accuracy 0.9081632653061225, Precision 0.7842460488406688, Recall 0.7085946754476091, F1 0.7347245519804356, Cohen Kappa 0.8131892233324853, Accuracy 0.9081632653061225\n",
            "Epoch 23: Loss 1.2530945560465625, Val Loss 15.75321974419785, Val Accuracy 0.9089481946624803, Precision 0.7840305892937471, Recall 0.7196029189933179, F1 0.7436132321045138, Cohen Kappa 0.8151896074792535, Accuracy 0.9089481946624803\n",
            "Epoch 24: Loss 0.8315300078375003, Val Loss 18.11122427211285, Val Accuracy 0.9215070643642073, Precision 0.8567497220941899, Recall 0.708016001386588, F1 0.745079211072096, Cohen Kappa 0.8397339130084738, Accuracy 0.9215070643642073\n",
            "Epoch 25: Loss 1.0477124810577152, Val Loss 16.814244707076796, Val Accuracy 0.9065934065934066, Precision 0.7373936401349641, Recall 0.7198239152773063, F1 0.7276938005619815, Cohen Kappa 0.8123362958928527, Accuracy 0.9065934065934066\n",
            "Epoch 26: Loss 1.8946230816109164, Val Loss 18.431365587806795, Val Accuracy 0.8893249607535322, Precision 0.6968420763827918, Recall 0.7142890042305842, F1 0.7039990982692211, Cohen Kappa 0.7829872982200112, Accuracy 0.8893249607535322\n",
            "Epoch 27: Loss 4.177622298344431, Val Loss 13.468425109989766, Val Accuracy 0.9081632653061225, Precision 0.7372016973076715, Recall 0.7075724539529468, F1 0.7204006478325065, Cohen Kappa 0.8136623600667554, Accuracy 0.9081632653061225\n",
            "Epoch 28: Loss 2.3529171431364375, Val Loss 17.865996332017403, Val Accuracy 0.9065934065934066, Precision 0.7899509673135187, Recall 0.6744740578878247, F1 0.7038155698274746, Cohen Kappa 0.8077200636680131, Accuracy 0.9065934065934066\n",
            "Epoch 29: Loss 1.2522059577549953, Val Loss 17.954886369243468, Val Accuracy 0.9128728414442701, Precision 0.8036248846108002, Recall 0.6921221939001975, F1 0.721496799192017, Cohen Kappa 0.8223935314441594, Accuracy 0.9128728414442701\n",
            "Epoch 30: Loss 0.5592322157408489, Val Loss 19.882152443604355, Val Accuracy 0.9128728414442701, Precision 0.7882837212413274, Recall 0.6928888600211942, F1 0.7192371573257205, Cohen Kappa 0.822993319723276, Accuracy 0.9128728414442701\n",
            "Epoch 31: Loss 1.466343667048477, Val Loss 16.77725884528627, Val Accuracy 0.8995290423861853, Precision 0.7316879979923457, Recall 0.7357507269877095, F1 0.7336848762000373, Cohen Kappa 0.7990246523614036, Accuracy 0.8995290423861853\n",
            "Epoch 32: Loss 2.0512628572478206, Val Loss 17.305933772084245, Val Accuracy 0.9065934065934066, Precision 0.7328442798072198, Recall 0.706442007940611, F1 0.7181100759946405, Cohen Kappa 0.8103172805879431, Accuracy 0.9065934065934066\n",
            "Epoch 33: Loss 2.7345682434461196, Val Loss 17.336430553838, Val Accuracy 0.9073783359497645, Precision 0.7916161632131088, Recall 0.7112238946122614, F1 0.7368011025357045, Cohen Kappa 0.8132628446076373, Accuracy 0.9073783359497645\n",
            "Epoch 34: Loss 1.6288980988045978, Val Loss 17.771025307967648, Val Accuracy 0.9120879120879121, Precision 0.7559464387764697, Recall 0.7118041235389471, F1 0.7293700355549589, Cohen Kappa 0.8217003989898422, Accuracy 0.9120879120879121\n",
            "Epoch 35: Loss 0.9541639138205937, Val Loss 18.564801038564838, Val Accuracy 0.8995290423861853, Precision 0.7620490964964587, Recall 0.7128202429193031, F1 0.73243817063552, Cohen Kappa 0.7962290274169626, Accuracy 0.8995290423861853\n",
            "Epoch 36: Loss 1.7355028427094794, Val Loss 18.154220183569123, Val Accuracy 0.9081632653061225, Precision 0.8138827531522347, Recall 0.6678448147841086, F1 0.6951952696336967, Cohen Kappa 0.8119032776665901, Accuracy 0.9081632653061225\n",
            "Epoch 37: Loss 0.3208760408600142, Val Loss 20.436069390312696, Val Accuracy 0.9136577708006279, Precision 0.8155468169339023, Recall 0.7018526605775781, F1 0.734228058634632, Cohen Kappa 0.8236576134007128, Accuracy 0.9136577708006279\n",
            "Epoch 38: Loss 0.4656547505791764, Val Loss 21.306606342398254, Val Accuracy 0.9191522762951334, Precision 0.8347609065650664, Recall 0.7069592208022485, F1 0.7407324410336823, Cohen Kappa 0.8353683016671183, Accuracy 0.9191522762951334\n",
            "Epoch 39: Loss 0.40233242869209107, Val Loss 22.11492368122697, Val Accuracy 0.9215070643642073, Precision 0.8456998254799301, Recall 0.7002563122705362, F1 0.7323833439295511, Cohen Kappa 0.8407695057355474, Accuracy 0.9215070643642073\n",
            "Epoch 40: Loss 0.3926350892231625, Val Loss 23.075523603822603, Val Accuracy 0.9105180533751962, Precision 0.8036538282130222, Recall 0.689020970326533, F1 0.7198200365047338, Cohen Kappa 0.8167526319508231, Accuracy 0.9105180533751962\n",
            "Epoch 41: Loss 0.2639804495016307, Val Loss 23.657103264599442, Val Accuracy 0.9097331240188383, Precision 0.7484827720596221, Recall 0.6883279696335323, F1 0.7091636713729738, Cohen Kappa 0.8157987377102768, Accuracy 0.9097331240188383\n",
            "Epoch 42: Loss 2.175537672682225, Val Loss 16.288612879478023, Val Accuracy 0.9097331240188383, Precision 0.7669206902529052, Recall 0.6991543232335714, F1 0.7225852890176877, Cohen Kappa 0.816123546502507, Accuracy 0.9097331240188383\n",
            "Epoch 43: Loss 1.451611623474946, Val Loss 17.097696093173, Val Accuracy 0.9073783359497645, Precision 0.7336244814314989, Recall 0.7109683392385958, F1 0.7204418769636161, Cohen Kappa 0.8140941771801258, Accuracy 0.9073783359497645\n",
            "Epoch 44: Loss 0.9370807093059739, Val Loss 19.07524207959068, Val Accuracy 0.9058084772370487, Precision 0.7609293659926571, Recall 0.7160642501003182, F1 0.7345396664537249, Cohen Kappa 0.8084671357267424, Accuracy 0.9058084772370487\n",
            "Epoch 45: Loss 0.6533256293106433, Val Loss 19.503987588788732, Val Accuracy 0.9144427001569859, Precision 0.8105985237483954, Recall 0.7136275702442836, F1 0.7441224407753569, Cohen Kappa 0.8260114542313123, Accuracy 0.9144427001569859\n",
            "Epoch 46: Loss 0.21117753994150235, Val Loss 20.76305783111036, Val Accuracy 0.9120879120879121, Precision 0.7978167656419027, Recall 0.7112930127916158, F1 0.7399873954529538, Cohen Kappa 0.8209454923283687, Accuracy 0.9120879120879121\n",
            "Epoch 47: Loss 0.5444117805685664, Val Loss 21.51117437992434, Val Accuracy 0.9120879120879121, Precision 0.750377535884112, Recall 0.6906625270861998, F1 0.7113130192700856, Cohen Kappa 0.8207306562538477, Accuracy 0.9120879120879121\n",
            "Epoch 48: Loss 0.5672061602198255, Val Loss 21.574720871242334, Val Accuracy 0.8924646781789639, Precision 0.7974408780342032, Recall 0.6640444884031372, F1 0.6955459997564607, Cohen Kappa 0.7783512158820908, Accuracy 0.8924646781789639\n",
            "Epoch 49: Loss 2.231061133163621, Val Loss 19.557318209321238, Val Accuracy 0.9120879120879121, Precision 0.8067892108031779, Recall 0.6834139487174792, F1 0.7103113691266653, Cohen Kappa 0.8215364911648756, Accuracy 0.9120879120879121\n",
            "Epoch 50: Loss 1.2108816260533217, Val Loss 21.34671261348558, Val Accuracy 0.9160125588697017, Precision 0.8779173646007816, Recall 0.7026538857882519, F1 0.7438174453842592, Cohen Kappa 0.8276868080889286, Accuracy 0.9160125588697017\n",
            "Epoch 51: Loss 0.3795639582443755, Val Loss 22.42637272742286, Val Accuracy 0.9167974882260597, Precision 0.8602632932439954, Recall 0.6847608437651617, F1 0.7177627208715291, Cohen Kappa 0.8299493792026595, Accuracy 0.9167974882260597\n",
            "Epoch 52: Loss 0.21504498914535475, Val Loss 22.56059602323694, Val Accuracy 0.9128728414442701, Precision 0.8040671638250837, Recall 0.6918666385265317, F1 0.7215713900996755, Cohen Kappa 0.822205291069152, Accuracy 0.9128728414442701\n",
            "Epoch 53: Loss 1.0152601163282924, Val Loss 21.87562683387523, Val Accuracy 0.9152276295133438, Precision 0.8665751633986928, Recall 0.6954789728475275, F1 0.7303155167568209, Cohen Kappa 0.8278738051483236, Accuracy 0.9152276295133438\n",
            "Epoch 54: Loss 0.615236081141461, Val Loss 21.855460061211488, Val Accuracy 0.8979591836734694, Precision 0.7618881118881119, Recall 0.6448497597849897, F1 0.657484619074023, Cohen Kappa 0.7936955184019812, Accuracy 0.8979591836734694\n",
            "Epoch 55: Loss 2.2571060964664866, Val Loss 20.345770990258643, Val Accuracy 0.9128728414442701, Precision 0.8090244626765776, Recall 0.6815513956738238, F1 0.7105206466576623, Cohen Kappa 0.8219409038311654, Accuracy 0.9128728414442701\n",
            "Epoch 56: Loss 1.109262537522909, Val Loss 21.00875184149845, Val Accuracy 0.9089481946624803, Precision 0.7333803627513853, Recall 0.7090321207669442, F1 0.7198288045905971, Cohen Kappa 0.8156177909418361, Accuracy 0.9089481946624803\n",
            "Epoch 57: Loss 0.3996026193351554, Val Loss 21.93292355606536, Val Accuracy 0.9065934065934066, Precision 0.7728616891940213, Recall 0.6762629455034839, F1 0.7018665540618448, Cohen Kappa 0.8089863574283223, Accuracy 0.9065934065934066\n",
            "Epoch 58: Loss 0.10722652206550265, Val Loss 23.44103386673578, Val Accuracy 0.9073783359497645, Precision 0.7849328982732429, Recall 0.6970753211545692, F1 0.7249124635818228, Cohen Kappa 0.8109799414828944, Accuracy 0.9073783359497645\n",
            "Epoch 59: Loss 0.07638155454469597, Val Loss 23.425184610990073, Val Accuracy 0.9113029827315542, Precision 0.7658775966326631, Recall 0.6899695263931992, F1 0.713852633450704, Cohen Kappa 0.8191170834982441, Accuracy 0.9113029827315542\n",
            "Epoch 60: Loss 0.0984827978460201, Val Loss 25.152521105248525, Val Accuracy 0.9105180533751962, Precision 0.8128303942841223, Recall 0.6998473239265722, F1 0.7318991578626468, Cohen Kappa 0.8174388188252862, Accuracy 0.9105180533751962\n",
            "Epoch 61: Loss 0.0729124837046271, Val Loss 24.90931701230511, Val Accuracy 0.9128728414442701, Precision 0.8145924777581607, Recall 0.7011596598845774, F1 0.7334159074751723, Cohen Kappa 0.82211739844148, Accuracy 0.9128728414442701\n",
            "Epoch 62: Loss 0.08805414083439977, Val Loss 25.822425077445132, Val Accuracy 0.9113029827315542, Precision 0.810333267600079, Recall 0.6783765066721633, F1 0.7093085771825546, Cohen Kappa 0.8175707955125776, Accuracy 0.9113029827315542\n",
            "Epoch 63: Loss 0.24464393215958324, Val Loss 25.03668477896622, Val Accuracy 0.9120879120879121, Precision 0.8121961143322144, Recall 0.6777917304968358, F1 0.7096914651247533, Cohen Kappa 0.8186038824830603, Accuracy 0.9120879120879121\n",
            "Epoch 64: Loss 0.4680373512164522, Val Loss 25.679693334401236, Val Accuracy 0.9073783359497645, Precision 0.7404103790029385, Recall 0.6784892784384783, F1 0.6974546089246223, Cohen Kappa 0.8118441605254726, Accuracy 0.9073783359497645\n",
            "Epoch 65: Loss 2.196961217489047, Val Loss 20.43602921021693, Val Accuracy 0.9113029827315542, Precision 0.7639248350001441, Recall 0.6806765050351538, F1 0.7039516714973105, Cohen Kappa 0.81904023269524, Accuracy 0.9113029827315542\n",
            "Epoch 66: Loss 0.6190775652603406, Val Loss 22.15260848240132, Val Accuracy 0.9073783359497645, Precision 0.7353638871693758, Recall 0.7290432712073556, F1 0.7321009200903643, Cohen Kappa 0.8134854908207994, Accuracy 0.9073783359497645\n",
            "Epoch 67: Loss 0.2699707628449559, Val Loss 24.88809555776207, Val Accuracy 0.9128728414442701, Precision 0.8589052642617263, Recall 0.6807847295528271, F1 0.7150061022899705, Cohen Kappa 0.8212323130425548, Accuracy 0.9128728414442701\n",
            "Epoch 68: Loss 0.19108730345556602, Val Loss 25.520335417285537, Val Accuracy 0.9065934065934066, Precision 0.7105710517372832, Recall 0.699448984945556, F1 0.7045684497390581, Cohen Kappa 0.8121795967719956, Accuracy 0.9065934065934066\n",
            "Epoch 69: Loss 0.08913346670039601, Val Loss 24.07466581059009, Val Accuracy 0.9144427001569859, Precision 0.7466464754055736, Recall 0.6824262863124941, F1 0.7024717737177436, Cohen Kappa 0.8255815998171235, Accuracy 0.9144427001569859\n",
            "Epoch 70: Loss 0.3590571614078293, Val Loss 24.040958045969617, Val Accuracy 0.9073783359497645, Precision 0.7688196452670137, Recall 0.7061127871389492, F1 0.7297167047871272, Cohen Kappa 0.8106726177282528, Accuracy 0.9073783359497645\n",
            "Epoch 71: Loss 0.5705487348100462, Val Loss 23.668970154471367, Val Accuracy 0.9034536891679749, Precision 0.7901541292845641, Recall 0.6624090337577765, F1 0.6897595781393653, Cohen Kappa 0.8011716385810916, Accuracy 0.9034536891679749\n",
            "Epoch 72: Loss 0.10513278373343127, Val Loss 24.241625021107893, Val Accuracy 0.9097331240188383, Precision 0.8829921270927258, Recall 0.66923081617011, F1 0.7003559743181564, Cohen Kappa 0.815039716405173, Accuracy 0.9097331240188383\n",
            "Epoch 73: Loss 0.45792836414734595, Val Loss 24.72760686723842, Val Accuracy 0.9175824175824175, Precision 0.88720633824673, Recall 0.6761608231001169, F1 0.7059301007738509, Cohen Kappa 0.8318390723681564, Accuracy 0.9175824175824175\n",
            "Epoch 74: Loss 0.4507771432883061, Val Loss 24.438191524237254, Val Accuracy 0.9113029827315542, Precision 0.8165622469419938, Recall 0.669594596061449, F1 0.6973679968444366, Cohen Kappa 0.8180758975395852, Accuracy 0.9113029827315542\n",
            "Epoch 75: Loss 0.10026950543231372, Val Loss 26.37495138117177, Val Accuracy 0.9144427001569859, Precision 0.7622576695193283, Recall 0.7025456612705788, F1 0.7240306983450511, Cohen Kappa 0.8258154747345513, Accuracy 0.9144427001569859\n",
            "Epoch 76: Loss 0.1855084511080829, Val Loss 24.974687223668695, Val Accuracy 0.9128728414442701, Precision 0.8171834556607452, Recall 0.6707250420737848, F1 0.6982661944446517, Cohen Kappa 0.82142261823582, Accuracy 0.9128728414442701\n",
            "Epoch 77: Loss 0.027149948036576887, Val Loss 25.173049990789934, Val Accuracy 0.9144427001569859, Precision 0.8101449853507617, Recall 0.6826818416861596, F1 0.7116460327095191, Cohen Kappa 0.8251491758342074, Accuracy 0.9144427001569859\n",
            "Epoch 78: Loss 0.21705417307597585, Val Loss 25.010970291652484, Val Accuracy 0.8995290423861853, Precision 0.7271760616687276, Recall 0.7329396178773878, F1 0.7296406668623, Cohen Kappa 0.7979191141116581, Accuracy 0.8995290423861853\n",
            "Epoch 79: Loss 0.3988097392919059, Val Loss 24.035674860867402, Val Accuracy 0.9152276295133438, Precision 0.825417147986538, Recall 0.6916456422425434, F1 0.725606941752054, Cohen Kappa 0.8258042462683732, Accuracy 0.9152276295133438\n",
            "Epoch 80: Loss 0.07085862682032484, Val Loss 25.726369633107424, Val Accuracy 0.9175824175824175, Precision 0.8341872253501075, Recall 0.6846871783371656, F1 0.7159835367565336, Cohen Kappa 0.8313508197961383, Accuracy 0.9175824175824175\n",
            "Epoch 81: Loss 0.05931718901462801, Val Loss 27.040351386299108, Val Accuracy 0.9144427001569859, Precision 0.8946591040232162, Recall 0.6824262863124941, F1 0.7185932282833568, Cohen Kappa 0.8246027966852043, Accuracy 0.9144427001569859\n",
            "Epoch 82: Loss 0.07809688417201066, Val Loss 27.799208795613275, Val Accuracy 0.9120879120879121, Precision 0.8156602560638871, Recall 0.6999555484442453, F1 0.7332108438476173, Cohen Kappa 0.8199420535651191, Accuracy 0.9120879120879121\n",
            "Epoch 83: Loss 0.01990209549194688, Val Loss 27.13620870435588, Val Accuracy 0.9120879120879121, Precision 0.8021972049689441, Recall 0.6994444376969143, F1 0.7307562057438575, Cohen Kappa 0.8197887802450674, Accuracy 0.9120879120879121\n",
            "Epoch 84: Loss 0.025935740303499655, Val Loss 27.00073370128844, Val Accuracy 0.9160125588697017, Precision 0.87032936930256, Recall 0.6928497536828754, F1 0.7308267265775205, Cohen Kappa 0.827711199694648, Accuracy 0.9160125588697017\n",
            "Epoch 85: Loss 0.023812692936994395, Val Loss 27.19659673345013, Val Accuracy 0.9152276295133438, Precision 0.7646813183637494, Recall 0.7138094601899531, F1 0.7334258828987613, Cohen Kappa 0.8279110488530905, Accuracy 0.9152276295133438\n",
            "Epoch 86: Loss 0.01955561696035346, Val Loss 27.94779131203528, Val Accuracy 0.9183673469387755, Precision 0.847118790396177, Recall 0.6941620896408806, F1 0.7299365391003719, Cohen Kappa 0.8324585085195839, Accuracy 0.9183673469387755\n",
            "Epoch 87: Loss 0.008463192442521361, Val Loss 26.673696955694112, Val Accuracy 0.9136577708006279, Precision 0.8222414365401275, Recall 0.6920485284722013, F1 0.7244615407687348, Cohen Kappa 0.823457679729505, Accuracy 0.9136577708006279\n",
            "Epoch 88: Loss 0.01811393608263323, Val Loss 29.739687531576195, Val Accuracy 0.9144427001569859, Precision 0.8169865956751202, Recall 0.7020345505232474, F1 0.7349672219160833, Cohen Kappa 0.8249512478901397, Accuracy 0.9144427001569859\n",
            "Epoch 89: Loss 0.7595906531605733, Val Loss 23.775503074772132, Val Accuracy 0.8979591836734694, Precision 0.7238454944711066, Recall 0.7655660095334974, F1 0.7405594132667, Cohen Kappa 0.7977209717014546, Accuracy 0.8979591836734694\n",
            "Epoch 90: Loss 0.5884470521859111, Val Loss 27.11049350901606, Val Accuracy 0.9128728414442701, Precision 0.8049587846638261, Recall 0.7310831669480388, F1 0.7588506287540415, Cohen Kappa 0.8224693400756502, Accuracy 0.9128728414442701\n",
            "Epoch 91: Loss 0.22036859144890997, Val Loss 25.5181543851063, Val Accuracy 0.9144427001569859, Precision 0.8199276930289588, Recall 0.7221539254813322, F1 0.7547965641594231, Cohen Kappa 0.8254338195732955, Accuracy 0.9144427001569859\n",
            "Epoch 92: Loss 0.2331327695205765, Val Loss 27.470688211591323, Val Accuracy 0.9136577708006279, Precision 0.8122909801000588, Recall 0.7059415465562277, F1 0.7345177793815783, Cohen Kappa 0.8258132918354486, Accuracy 0.9136577708006279\n",
            "Epoch 93: Loss 0.9093068460672065, Val Loss 24.715602697572876, Val Accuracy 0.9081632653061225, Precision 0.7565024337613954, Recall 0.7168654753109922, F1 0.7336103479322132, Cohen Kappa 0.8131634659857934, Accuracy 0.9081632653061225\n",
            "Epoch 94: Loss 0.07720012672091947, Val Loss 26.449953749393174, Val Accuracy 0.9152276295133438, Precision 0.8230874602287908, Recall 0.6929234191108714, F1 0.7253217558224981, Cohen Kappa 0.8266675400980594, Accuracy 0.9152276295133438\n",
            "Epoch 95: Loss 0.02557348438916307, Val Loss 26.894148155232635, Val Accuracy 0.9136577708006279, Precision 0.7906105129278308, Recall 0.6917929730985356, F1 0.7197753555026836, Cohen Kappa 0.8236576134007128, Accuracy 0.9136577708006279\n",
            "Epoch 96: Loss 0.037606463451453465, Val Loss 26.16957932344885, Val Accuracy 0.9105180533751962, Precision 0.7682873057834351, Recall 0.7104181221529456, F1 0.7319549075428186, Cohen Kappa 0.818312147926307, Accuracy 0.9105180533751962\n",
            "Epoch 97: Loss 0.01686918448106045, Val Loss 27.457913149512404, Val Accuracy 0.9120879120879121, Precision 0.7977880924656057, Recall 0.7110374574179502, F1 0.7398335606019043, Cohen Kappa 0.820882332265483, Accuracy 0.9120879120879121\n",
            "Epoch 98: Loss 0.021093181488846924, Val Loss 28.009539449878403, Val Accuracy 0.9120879120879121, Precision 0.7876896164096346, Recall 0.7203304787759958, F1 0.7456351024147634, Cohen Kappa 0.820806751393982, Accuracy 0.9120879120879121\n",
            "Epoch 99: Loss 0.01728469189871118, Val Loss 27.984532645556698, Val Accuracy 0.9136577708006279, Precision 0.8518133639421602, Recall 0.7018526605775781, F1 0.7394836347047553, Cohen Kappa 0.8233951630891606, Accuracy 0.9136577708006279\n",
            "Epoch 100: Loss 0.0073132651384577585, Val Loss 28.76951680527391, Val Accuracy 0.9136577708006279, Precision 0.8685221599225489, Recall 0.6912818623512044, F1 0.7291538875936429, Cohen Kappa 0.8229435539400555, Accuracy 0.9136577708006279\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, accuracy_score\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "# Check if GPU is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, input_length):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(768, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.res1 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm1d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.res2 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm1d(128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.fc1 = nn.Linear(128 * (input_length // 4), 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))\n",
        "        x = self.relu3(self.bn3(self.res1(x) + x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu4(self.bn4(self.conv3(x)))\n",
        "        x = self.relu5(self.bn5(self.res2(x) + x))\n",
        "        x = self.pool2(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        if self.alpha is not None:\n",
        "            alpha_t = self.alpha.gather(0, targets.data.view(-1))\n",
        "            F_loss = alpha_t * F_loss\n",
        "        return F_loss.mean()\n",
        "\n",
        "# Assume df is your DataFrame loaded with your data\n",
        "token_embeddings_np = np.array(df['layer_output'].tolist())\n",
        "labels = np.array(df['a'])\n",
        "input_length = token_embeddings_np.shape[1]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(token_embeddings_np, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to PyTorch tensors and permute dimensions\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# DataLoader with batch size optimized for multiple GPUs\n",
        "batch_size = 16  # Adjust batch size suitable for your GPU configuration\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "# Model instantiation and moving to GPU if available\n",
        "model = ConvNet(input_length).to(device)\n",
        "\n",
        "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "    model = nn.DataParallel(model)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
        "\n",
        "# Define Focal Loss\n",
        "criterion = FocalLoss(gamma=2)\n",
        "\n",
        "# Custom metrics for logging\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=1)\n",
        "    cohen_kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    return precision, recall, f1, cohen_kappa, accuracy\n",
        "\n",
        "# Create an empty DataFrame to store evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame(columns=['Epoch', 'Precision', 'Recall', 'F1', 'Cohen Kappa', 'Accuracy', 'Loss', 'Val_Loss', \"Val_Accuracy\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute validation metrics\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predicted.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision, recall, f1, cohen_kappa, accuracy = compute_metrics(all_labels, all_predictions)\n",
        "\n",
        "    # Append evaluation metrics to DataFrame\n",
        "    # evaluation_metrics = evaluation_metrics.append({'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy ,'Loss':total_loss, 'Val_Loss': total_val_loss, \"Val_Accuracy\":val_accuracy}, ignore_index=True)\n",
        "\n",
        "    # # Print and save metrics\n",
        "    # print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    # evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_A_L.csv', index=False)\n",
        "    # scheduler.step()\n",
        "\n",
        "\n",
        "    new_metrics = pd.DataFrame([{'Epoch': epoch+1, 'Precision': precision, 'Recall': recall, 'F1': f1, 'Cohen Kappa': cohen_kappa, 'Accuracy': accuracy, 'Loss': total_loss, 'Val_Loss': total_val_loss, 'Val_Accuracy': val_accuracy}])\n",
        "    evaluation_metrics = pd.concat([evaluation_metrics, new_metrics], ignore_index=True)\n",
        "\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Loss {total_loss}, Val Loss {total_val_loss}, Val Accuracy {val_accuracy}, Precision {precision}, Recall {recall}, F1 {f1}, Cohen Kappa {cohen_kappa}, Accuracy {accuracy}')\n",
        "    evaluation_metrics.to_csv('/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/eva_A_L.csv', index=False)\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCvSYmvnF75O"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.save(model.state_dict(), '/home/leili/Vul/FinetuneLLM/BertCNN/GPT35Turbo/model-A')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f1fc22f25b7ff86ab71b39773a0fc35f3d0ff49e86d16dc027a0214df64a378"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}